{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import traceback\n",
    "from collections import OrderedDict, defaultdict\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchnet.meter as tnt\n",
    "# script_dir = os.path.dirname(__file__)\n",
    "script_dir = os.path.abspath('/host/model_compression/distiller/examples/style_transfer_compression')\n",
    "module_path = os.path.abspath(os.path.join(script_dir, '..', '..'))\n",
    "try:\n",
    "    import distiller\n",
    "except ImportError:\n",
    "    sys.path.append(module_path)\n",
    "    import distiller\n",
    "import apputils\n",
    "from distiller.data_loggers import *\n",
    "import distiller.quantization as quantization\n",
    "from models import ALL_MODEL_NAMES, create_model\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "import re\n",
    "\n",
    "sys.path.append('/host/model_compression/distiller/examples/style_transfer_compression/network')\n",
    "import utils\n",
    "from transformer_net import *\n",
    "from vgg import *\n",
    "\n",
    "# Logger handle\n",
    "msglogger = None\n",
    "\n",
    "\n",
    "def float_range(val_str):\n",
    "    val = float(val_str)\n",
    "    if val < 0 or val >= 1:\n",
    "        raise argparse.ArgumentTypeError('Must be >= 0 and < 1 (received {0})'.format(val_str))\n",
    "    return val\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Distiller image classification model compression')\n",
    "parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',\n",
    "                    choices=ALL_MODEL_NAMES,\n",
    "                    help='model architecture: ' +\n",
    "                    ' | '.join(ALL_MODEL_NAMES) +\n",
    "                    ' (default: resnet18)')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 256)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model')\n",
    "parser.add_argument('--act-stats', dest='activation_stats', choices=[\"train\", \"valid\", \"test\"], default=None,\n",
    "                    help='collect activation statistics (WARNING: this slows down training)')\n",
    "parser.add_argument('--masks-sparsity', dest='masks_sparsity', action='store_true', default=False,\n",
    "                    help='print masks sparsity table at end of each epoch')\n",
    "parser.add_argument('--param-hist', dest='log_params_histograms', action='store_true', default=False,\n",
    "                    help='log the paramter tensors histograms to file (WARNING: this can use significant disk space)')\n",
    "SUMMARY_CHOICES = ['sparsity', 'compute', 'model', 'modules', 'png', 'png_w_params', 'onnx']\n",
    "parser.add_argument('--summary', type=str, choices=SUMMARY_CHOICES,\n",
    "                    help='print a summary of the model, and exit - options: ' +\n",
    "                    ' | '.join(SUMMARY_CHOICES))\n",
    "parser.add_argument('--compress', dest='compress', type=str, nargs='?', action='store',\n",
    "                    help='configuration file for pruning the model (default is to use hard-coded schedule)')\n",
    "parser.add_argument('--sense', dest='sensitivity', choices=['element', 'filter', 'channel'],\n",
    "                    help='test the sensitivity of layers to pruning')\n",
    "parser.add_argument('--extras', default=None, type=str,\n",
    "                    help='file with extra configuration information')\n",
    "parser.add_argument('--deterministic', '--det', action='store_true',\n",
    "                    help='Ensure deterministic execution for re-producible results.')\n",
    "parser.add_argument('--gpus', metavar='DEV_ID', default=None,\n",
    "                    help='Comma-separated list of GPU device IDs to be used (default is to use all available devices)')\n",
    "parser.add_argument('--name', '-n', metavar='NAME', default=None, help='Experiment name')\n",
    "parser.add_argument('--out-dir', '-o', dest='output_dir', default='logs', help='Path to dump logs and checkpoints')\n",
    "parser.add_argument('--validation-size', '--vs', type=float_range, default=0.1,\n",
    "                    help='Portion of training dataset to set aside for validation')\n",
    "parser.add_argument('--adc', dest='ADC', action='store_true', help='temp HACK')\n",
    "parser.add_argument('--adc-params', dest='ADC_params', default=None, help='temp HACK')\n",
    "parser.add_argument('--confusion', dest='display_confusion', default=False, action='store_true',\n",
    "                    help='Display the confusion matrix')\n",
    "parser.add_argument('--earlyexit_lossweights', type=float, nargs='*', dest='earlyexit_lossweights', default=None,\n",
    "                    help='List of loss weights for early exits (e.g. --lossweights 0.1 0.3)')\n",
    "parser.add_argument('--earlyexit_thresholds', type=float, nargs='*', dest='earlyexit_thresholds', default=None,\n",
    "                    help='List of EarlyExit thresholds (e.g. --earlyexit 1.2 0.9)')\n",
    "parser.add_argument('--num-best-scores', dest='num_best_scores', default=1, type=int,\n",
    "                    help='number of best scores to track and report (default: 1)')\n",
    "parser.add_argument('--load-serialized', dest='load_serialized', action='store_true', default=False,\n",
    "                    help='Load a model without DataParallel wrapping it')\n",
    "                    \n",
    "quant_group = parser.add_argument_group('Arguments controlling quantization at evaluation time'\n",
    "                                        '(\"post-training quantization)')\n",
    "quant_group.add_argument('--quantize-eval', '--qe', action='store_true',\n",
    "                         help='Apply linear-symmetric quantization to model before evaluation. Applicable only if'\n",
    "                              '--evaluate is also set')\n",
    "quant_group.add_argument('--qe-bits-acts', '--qeba', type=int, default=8, metavar='NUM_BITS',\n",
    "                         help='Number of bits for quantization of activations')\n",
    "quant_group.add_argument('--qe-bits-wts', '--qebw', type=int, default=8, metavar='NUM_BITS',\n",
    "                         help='Number of bits for quantization of weights')\n",
    "quant_group.add_argument('--qe-bits-accum', type=int, default=32, metavar='NUM_BITS',\n",
    "                         help='Number of bits for quantization of the accumulator')\n",
    "quant_group.add_argument('--qe-clip-acts', '--qeca', action='store_true',\n",
    "                         help='Enable clipping of activations using max-abs-value averaging over batch')\n",
    "quant_group.add_argument('--qe-no-clip-layers', '--qencl', type=str, nargs='+', metavar='LAYER_NAME', default=[],\n",
    "                         help='List of fully-qualified layer names for which not to clip activations. Applicable'\n",
    "                              'only if --qe-clip-acts is also set')\n",
    "\n",
    "distiller.knowledge_distillation.add_distillation_args(parser, ALL_MODEL_NAMES, True)\n",
    "\n",
    "def check_pytorch_version():\n",
    "    if torch.__version__ < '0.4.0':\n",
    "        print(\"\\nNOTICE:\")\n",
    "        print(\"The Distiller \\'master\\' branch now requires at least PyTorch version 0.4.0 due to \"\n",
    "              \"PyTorch API changes which are not backward-compatible.\\n\"\n",
    "              \"Please install PyTorch 0.4.0 or its derivative.\\n\"\n",
    "              \"If you are using a virtual environment, do not forget to update it:\\n\"\n",
    "              \"  1. Deactivate the old environment\\n\"\n",
    "              \"  2. Install the new environment\\n\"\n",
    "              \"  3. Activate the new environment\")\n",
    "        exit(1)\n",
    "    else:\n",
    "        print(\"torch version: \" + torch.__version__)\n",
    "        \n",
    "def create_activation_stats_collectors(model, collection_phase):\n",
    "    \"\"\"Create objects that collect activation statistics.\n",
    "\n",
    "    This is a utility function that creates two collectors:\n",
    "    1. Fine-grade sparsity levels of the activations\n",
    "    2. L1-magnitude of each of the activation channels\n",
    "\n",
    "    Args:\n",
    "        model - the model on which we want to collect statistics\n",
    "        phase - the statistics collection phase which is either \"train\" (for training),\n",
    "                or \"valid\" (for validation)\n",
    "\n",
    "    WARNING! Enabling activation statsitics collection will significantly slow down training!\n",
    "    \"\"\"\n",
    "    class missingdict(dict):\n",
    "        \"\"\"This is a little trick to prevent KeyError\"\"\"\n",
    "        def __missing__(self, key):\n",
    "            return None  # note, does *not* set self[key] - we don't want defaultdict's behavior\n",
    "\n",
    "    distiller.utils.assign_layer_fq_names(model)\n",
    "\n",
    "    activations_collectors = {\"train\": missingdict(), \"valid\": missingdict(), \"test\": missingdict()}\n",
    "    if collection_phase is None:\n",
    "        return activations_collectors\n",
    "    collectors = missingdict()\n",
    "    collectors[\"sparsity\"] = SummaryActivationStatsCollector(model, \"sparsity\", distiller.utils.sparsity)\n",
    "    collectors[\"l1_channels\"] = SummaryActivationStatsCollector(model, \"l1_channels\",\n",
    "                                                                distiller.utils.activation_channels_l1)\n",
    "    collectors[\"apoz_channels\"] = SummaryActivationStatsCollector(model, \"apoz_channels\",\n",
    "                                                                  distiller.utils.activation_channels_apoz)\n",
    "    collectors[\"records\"] = RecordsActivationStatsCollector(model, classes=[torch.nn.Conv2d])\n",
    "    activations_collectors[collection_phase] = collectors\n",
    "    return activations_collectors       \n",
    "        \n",
    "def save_collectors_data(collectors, directory):\n",
    "    \"\"\"Utility function that saves all activation statistics to Excel workbooks\n",
    "    \"\"\"\n",
    "    for name, collector in collectors.items():\n",
    "        collector.to_xlsx(os.path.join(directory, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "args = Object()\n",
    "args.dataset = '/host/dataset/COCO'\n",
    "args.epochs = 1\n",
    "args.batch_size = 2\n",
    "args.output_dir = './logs'\n",
    "args.name = None\n",
    "args.deterministic = False\n",
    "args.cuda = 1\n",
    "args.earlyexit_thresholds = None\n",
    "args.resume = None\n",
    "args.lr = 1e-4\n",
    "args.style_size = None\n",
    "args.log_interval = 2\n",
    "args.log_params_histograms = False\n",
    "args.activation_stats = False\n",
    "args.image_size = 256\n",
    "args.pretrained = 'pretrained/models/style4_transfer.model'\n",
    "args.content_weight = 1e5\n",
    "args.style_weight = 1e10\n",
    "args.style_image = \"./pretrained/images/style_images/style4.jpg\"\n",
    "args.compress = './style_transfer_L1RankedFilters_v1.yaml'\n",
    "args.num_best_scores = 1\n",
    "args.masks_sparsity = False\n",
    "args.display_confusion = False\n",
    "print(args.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['betas', 'lr', 'eps', 'amsgrad', 'params', 'weight_decay'])\n",
      "torch.Size([24, 3, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.param_groups[0].keys())\n",
    "print(optimizer.param_groups[0]['params'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log file for this run: /host/model_compression/distiller/examples/style_transfer_compression/logs/2018.11.18-062004/2018.11.18-062004.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 0.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distiller: 0.3.0-pre\n",
      "Loaded pretrained model from pretrained/models/style4_transfer.model\n",
      "\n",
      "Optimizer Type: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer Args: {'amsgrad': False, 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "Logging to TensorBoard - remember to execute the server:\n",
      "> tensorboard --logdir='./logs'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "\ttraining=82783\n",
      "\n",
      "Reading compression schedule from: ./style_transfer_L1RankedFilters_v1.yaml\n",
      "Created masker for parameter conv1.conv2d.weight\n",
      "Created masker for parameter conv1.conv2d.bias\n",
      "Created masker for parameter in1.weight\n",
      "Created masker for parameter in1.bias\n",
      "Created masker for parameter conv2.conv2d.weight\n",
      "Created masker for parameter conv2.conv2d.bias\n",
      "Created masker for parameter in2.weight\n",
      "Created masker for parameter in2.bias\n",
      "Created masker for parameter conv3.conv2d.weight\n",
      "Created masker for parameter conv3.conv2d.bias\n",
      "Created masker for parameter in3.weight\n",
      "Created masker for parameter in3.bias\n",
      "Created masker for parameter res1.conv1.conv2d.weight\n",
      "Created masker for parameter res1.conv1.conv2d.bias\n",
      "Created masker for parameter res1.in1.weight\n",
      "Created masker for parameter res1.in1.bias\n",
      "Created masker for parameter res1.conv2.conv2d.weight\n",
      "Created masker for parameter res1.conv2.conv2d.bias\n",
      "Created masker for parameter res1.in2.weight\n",
      "Created masker for parameter res1.in2.bias\n",
      "Created masker for parameter res2.conv1.conv2d.weight\n",
      "Created masker for parameter res2.conv1.conv2d.bias\n",
      "Created masker for parameter res2.in1.weight\n",
      "Created masker for parameter res2.in1.bias\n",
      "Created masker for parameter res2.conv2.conv2d.weight\n",
      "Created masker for parameter res2.conv2.conv2d.bias\n",
      "Created masker for parameter res2.in2.weight\n",
      "Created masker for parameter res2.in2.bias\n",
      "Created masker for parameter res3.conv1.conv2d.weight\n",
      "Created masker for parameter res3.conv1.conv2d.bias\n",
      "Created masker for parameter res3.in1.weight\n",
      "Created masker for parameter res3.in1.bias\n",
      "Created masker for parameter res3.conv2.conv2d.weight\n",
      "Created masker for parameter res3.conv2.conv2d.bias\n",
      "Created masker for parameter res3.in2.weight\n",
      "Created masker for parameter res3.in2.bias\n",
      "Created masker for parameter res4.conv1.conv2d.weight\n",
      "Created masker for parameter res4.conv1.conv2d.bias\n",
      "Created masker for parameter res4.in1.weight\n",
      "Created masker for parameter res4.in1.bias\n",
      "Created masker for parameter res4.conv2.conv2d.weight\n",
      "Created masker for parameter res4.conv2.conv2d.bias\n",
      "Created masker for parameter res4.in2.weight\n",
      "Created masker for parameter res4.in2.bias\n",
      "Created masker for parameter res5.conv1.conv2d.weight\n",
      "Created masker for parameter res5.conv1.conv2d.bias\n",
      "Created masker for parameter res5.in1.weight\n",
      "Created masker for parameter res5.in1.bias\n",
      "Created masker for parameter res5.conv2.conv2d.weight\n",
      "Created masker for parameter res5.conv2.conv2d.bias\n",
      "Created masker for parameter res5.in2.weight\n",
      "Created masker for parameter res5.in2.bias\n",
      "Created masker for parameter deconv1.conv2d.weight\n",
      "Created masker for parameter deconv1.conv2d.bias\n",
      "Created masker for parameter in4.weight\n",
      "Created masker for parameter in4.bias\n",
      "Created masker for parameter deconv2.conv2d.weight\n",
      "Created masker for parameter deconv2.conv2d.bias\n",
      "Created masker for parameter in5.weight\n",
      "Created masker for parameter in5.bias\n",
      "Created masker for parameter deconv3.conv2d.weight\n",
      "Created masker for parameter deconv3.conv2d.bias\n",
      "\n",
      "\n",
      "Pruner filter_pruner is about to prune\n",
      "L1RankedStructureParameterPruner - param: conv1.conv2d.weight pruned=0.250 goal=0.300 (8/32)\n",
      "L1RankedStructureParameterPruner - param: conv2.conv2d.weight pruned=0.312 goal=0.300 (20/64)\n",
      "L1RankedStructureParameterPruner - param: conv3.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res1.conv1.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res1.conv2.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res2.conv1.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res2.conv2.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res3.conv1.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res3.conv2.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res4.conv1.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res4.conv2.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res5.conv1.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: res5.conv2.conv2d.weight pruned=0.312 goal=0.300 (40/128)\n",
      "L1RankedStructureParameterPruner - param: deconv1.conv2d.weight pruned=0.312 goal=0.300 (20/64)\n",
      "L1RankedStructureParameterPruner - param: deconv2.conv2d.weight pruned=0.250 goal=0.300 (8/32)\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Masking parameter conv1.conv2d.weight\n",
      "No mask for parameter conv1.conv2d.bias\n",
      "No mask for parameter in1.weight\n",
      "No mask for parameter in1.bias\n",
      "Masking parameter conv2.conv2d.weight\n",
      "No mask for parameter conv2.conv2d.bias\n",
      "No mask for parameter in2.weight\n",
      "No mask for parameter in2.bias\n",
      "Masking parameter conv3.conv2d.weight\n",
      "No mask for parameter conv3.conv2d.bias\n",
      "No mask for parameter in3.weight\n",
      "No mask for parameter in3.bias\n",
      "Masking parameter res1.conv1.conv2d.weight\n",
      "No mask for parameter res1.conv1.conv2d.bias\n",
      "No mask for parameter res1.in1.weight\n",
      "No mask for parameter res1.in1.bias\n",
      "Masking parameter res1.conv2.conv2d.weight\n",
      "No mask for parameter res1.conv2.conv2d.bias\n",
      "No mask for parameter res1.in2.weight\n",
      "No mask for parameter res1.in2.bias\n",
      "Masking parameter res2.conv1.conv2d.weight\n",
      "No mask for parameter res2.conv1.conv2d.bias\n",
      "No mask for parameter res2.in1.weight\n",
      "No mask for parameter res2.in1.bias\n",
      "Masking parameter res2.conv2.conv2d.weight\n",
      "No mask for parameter res2.conv2.conv2d.bias\n",
      "No mask for parameter res2.in2.weight\n",
      "No mask for parameter res2.in2.bias\n",
      "Masking parameter res3.conv1.conv2d.weight\n",
      "No mask for parameter res3.conv1.conv2d.bias\n",
      "No mask for parameter res3.in1.weight\n",
      "No mask for parameter res3.in1.bias\n",
      "Masking parameter res3.conv2.conv2d.weight\n",
      "No mask for parameter res3.conv2.conv2d.bias\n",
      "No mask for parameter res3.in2.weight\n",
      "No mask for parameter res3.in2.bias\n",
      "Masking parameter res4.conv1.conv2d.weight\n",
      "No mask for parameter res4.conv1.conv2d.bias\n",
      "No mask for parameter res4.in1.weight\n",
      "No mask for parameter res4.in1.bias\n",
      "Masking parameter res4.conv2.conv2d.weight\n",
      "No mask for parameter res4.conv2.conv2d.bias\n",
      "No mask for parameter res4.in2.weight\n",
      "No mask for parameter res4.in2.bias\n",
      "Masking parameter res5.conv1.conv2d.weight\n",
      "No mask for parameter res5.conv1.conv2d.bias\n",
      "No mask for parameter res5.in1.weight\n",
      "No mask for parameter res5.in1.bias\n",
      "Masking parameter res5.conv2.conv2d.weight\n",
      "No mask for parameter res5.conv2.conv2d.bias\n",
      "No mask for parameter res5.in2.weight\n",
      "No mask for parameter res5.in2.bias\n",
      "Masking parameter deconv1.conv2d.weight\n",
      "No mask for parameter deconv1.conv2d.bias\n",
      "No mask for parameter in4.weight\n",
      "No mask for parameter in4.bias\n",
      "Masking parameter deconv2.conv2d.weight\n",
      "No mask for parameter deconv2.conv2d.bias\n",
      "No mask for parameter in5.weight\n",
      "No mask for parameter in5.bias\n",
      "No mask for parameter deconv3.conv2d.weight\n",
      "No mask for parameter deconv3.conv2d.bias\n",
      "Invoking create_thinning_recipe_filters\n",
      "dict_keys(['res4.in21', 'in11', 'res4', 'res2.conv1.conv2d', 'in31', 'relu3', 'res3.in21', 'relu', 'in41', 'res2', 'res1.conv2.conv2d', 'res2.in11', 'relu4', 'res5.conv1.reflection_pad', 'res4.conv1.reflection_pad', 'res4.in2', 'conv1.conv2d', 'res4.in1', 'deconv2.upsample_layer', 'conv1.reflection_pad', 'res5.conv2.reflection_pad', 'res2.in1', 'res5', 'res3.in11', 'res3.conv2.reflection_pad', 'deconv3.reflection_pad', 'res4.relu', 'res3.conv1.conv2d', 'res4.conv1.conv2d', 'in51', 'res3.in2', 'res1.in21', 'res5.in21', 'res1', 'res3.conv2.conv2d', 'in2', 'res1.in2', 'res1.conv1.reflection_pad', 'res4.in11', 'res2.conv1.reflection_pad', 'in4', 'deconv3.conv2d', 'res2.relu', 'res5.in2', 'conv2.conv2d', 'res2.in21', 'res1.in11', 'res5.relu', 'res4.conv2.conv2d', 'conv3.conv2d', 'res3.relu', 'conv3.reflection_pad', 'res2.conv2.conv2d', 'res3', 'res5.conv1.conv2d', 'relu1', 'in1', 'in21', 'res5.conv2.conv2d', 'res5.in11', 'res3.conv1.reflection_pad', 'deconv1.conv2d', 'res1.conv1.conv2d', 'deconv1.upsample_layer', 'deconv2.conv2d', 'res2.conv2.reflection_pad', 'res5.in1', 'in5', 'res1.relu', 'relu2', 'conv2.reflection_pad', 'deconv1.reflection_pad', 'res1.in1', 'deconv2.reflection_pad', 'res1.conv2.reflection_pad', 'res3.in1', 'in3', 'res2.in2', 'res4.conv2.reflection_pad'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In tensor conv1.conv2d.weight found 8/32 zero filters\n",
      "conv1.conv2d => conv1.conv2d\n",
      "[recipe] conv2.conv2d: setting in_channels = 24\n",
      "In tensor conv2.conv2d.weight found 20/64 zero filters\n",
      "conv2.conv2d => conv2.conv2d\n",
      "[recipe] conv3.conv2d: setting in_channels = 44\n",
      "In tensor conv3.conv2d.weight found 40/128 zero filters\n",
      "conv3.conv2d => conv3.conv2d\n",
      "[recipe] res1.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res2.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res3.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res4.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res5.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] deconv1.conv2d: setting in_channels = 88\n",
      "In tensor res1.conv1.conv2d.weight found 40/128 zero filters\n",
      "res1.conv1.conv2d => res1.conv1.conv2d\n",
      "[recipe] res1.conv2.conv2d: setting in_channels = 88\n",
      "In tensor res1.conv2.conv2d.weight found 40/128 zero filters\n",
      "res1.conv2.conv2d => res1.conv2.conv2d\n",
      "[recipe] res2.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res3.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res4.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res5.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] deconv1.conv2d: setting in_channels = 88\n",
      "In tensor res2.conv1.conv2d.weight found 40/128 zero filters\n",
      "res2.conv1.conv2d => res2.conv1.conv2d\n",
      "[recipe] res2.conv2.conv2d: setting in_channels = 88\n",
      "In tensor res2.conv2.conv2d.weight found 40/128 zero filters\n",
      "res2.conv2.conv2d => res2.conv2.conv2d\n",
      "[recipe] res3.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res4.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res5.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] deconv1.conv2d: setting in_channels = 88\n",
      "In tensor res3.conv1.conv2d.weight found 40/128 zero filters\n",
      "res3.conv1.conv2d => res3.conv1.conv2d\n",
      "[recipe] res3.conv2.conv2d: setting in_channels = 88\n",
      "In tensor res3.conv2.conv2d.weight found 40/128 zero filters\n",
      "res3.conv2.conv2d => res3.conv2.conv2d\n",
      "[recipe] res4.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] res5.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] deconv1.conv2d: setting in_channels = 88\n",
      "In tensor res4.conv1.conv2d.weight found 40/128 zero filters\n",
      "res4.conv1.conv2d => res4.conv1.conv2d\n",
      "[recipe] res4.conv2.conv2d: setting in_channels = 88\n",
      "In tensor res4.conv2.conv2d.weight found 40/128 zero filters\n",
      "res4.conv2.conv2d => res4.conv2.conv2d\n",
      "[recipe] res5.conv1.conv2d: setting in_channels = 88\n",
      "[recipe] deconv1.conv2d: setting in_channels = 88\n",
      "In tensor res5.conv1.conv2d.weight found 40/128 zero filters\n",
      "res5.conv1.conv2d => res5.conv1.conv2d\n",
      "[recipe] res5.conv2.conv2d: setting in_channels = 88\n",
      "In tensor res5.conv2.conv2d.weight found 40/128 zero filters\n",
      "res5.conv2.conv2d => res5.conv2.conv2d\n",
      "[recipe] deconv1.conv2d: setting in_channels = 88\n",
      "In tensor deconv1.conv2d.weight found 20/64 zero filters\n",
      "deconv1.conv2d => deconv1.conv2d\n",
      "[recipe] deconv2.conv2d: setting in_channels = 44\n",
      "In tensor deconv2.conv2d.weight found 8/32 zero filters\n",
      "deconv2.conv2d => deconv2.conv2d\n",
      "[recipe] deconv3.conv2d: setting in_channels = 24\n",
      "SKipping deconv3.conv2d shape=torch.Size([3, 32, 9, 9])\n",
      "[thinning] deconv3.conv2d: setting in_channels to 24\n",
      "[thinning] res5.in1: setting num_features to 88\n",
      "[thinning] conv2.conv2d: setting out_channels to 44\n",
      "[thinning] conv2.conv2d: setting in_channels to 24\n",
      "[thinning] res2.conv1.conv2d: setting out_channels to 88\n",
      "[thinning] res2.conv1.conv2d: setting in_channels to 88\n",
      "[thinning] res5.in2: setting num_features to 88\n",
      "[thinning] deconv2.conv2d: setting out_channels to 24\n",
      "[thinning] deconv2.conv2d: setting in_channels to 44\n",
      "[thinning] res1.conv2.conv2d: setting out_channels to 88\n",
      "[thinning] res1.conv2.conv2d: setting in_channels to 88\n",
      "[thinning] conv3.conv2d: setting out_channels to 88\n",
      "[thinning] conv3.conv2d: setting in_channels to 44\n",
      "[thinning] res2.conv2.conv2d: setting out_channels to 88\n",
      "[thinning] res2.conv2.conv2d: setting in_channels to 88\n",
      "[thinning] res4.in2: setting num_features to 88\n",
      "[thinning] conv1.conv2d: setting out_channels to 24\n",
      "[thinning] res5.conv1.conv2d: setting out_channels to 88\n",
      "[thinning] res5.conv1.conv2d: setting in_channels to 88\n",
      "[thinning] res4.in1: setting num_features to 88\n",
      "[thinning] in1: setting num_features to 24\n",
      "[thinning] res4.conv2.conv2d: setting out_channels to 88\n",
      "[thinning] res4.conv2.conv2d: setting in_channels to 88\n",
      "[thinning] res5.conv2.conv2d: setting out_channels to 88\n",
      "[thinning] res5.conv2.conv2d: setting in_channels to 88\n",
      "[thinning] in5: setting num_features to 24\n",
      "[thinning] res2.in1: setting num_features to 88\n",
      "[thinning] deconv1.conv2d: setting out_channels to 44\n",
      "[thinning] deconv1.conv2d: setting in_channels to 88\n",
      "[thinning] res1.conv1.conv2d: setting out_channels to 88\n",
      "[thinning] res1.conv1.conv2d: setting in_channels to 88\n",
      "[thinning] res3.conv1.conv2d: setting out_channels to 88\n",
      "[thinning] res3.conv1.conv2d: setting in_channels to 88\n",
      "[thinning] res4.conv1.conv2d: setting out_channels to 88\n",
      "[thinning] res4.conv1.conv2d: setting in_channels to 88\n",
      "[thinning] in4: setting num_features to 44\n",
      "[thinning] res3.in2: setting num_features to 88\n",
      "[thinning] res3.conv2.conv2d: setting out_channels to 88\n",
      "[thinning] res3.conv2.conv2d: setting in_channels to 88\n",
      "[thinning] in2: setting num_features to 44\n",
      "[thinning] res1.in2: setting num_features to 88\n",
      "[thinning] res1.in1: setting num_features to 88\n",
      "[thinning] res3.in1: setting num_features to 88\n",
      "[thinning] in3: setting num_features to 88\n",
      "[thinning] res2.in2: setting num_features to 88\n",
      "[thinning] changed param res2.in1.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res3.conv1.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res3.conv1.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param res5.conv2.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res4.in2.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param conv3.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param in4.bias shape: 44\n",
      "torch.Size([44])\n",
      "[thinning] changed param res3.conv1.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res5.in2.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res4.in1.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param in4.weight shape: 44\n",
      "torch.Size([44])\n",
      "[thinning] changed param res1.conv1.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res1.conv1.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param conv1.conv2d.bias shape: 24\n",
      "torch.Size([24])\n",
      "[thinning] changed param in1.bias shape: 24\n",
      "torch.Size([24])\n",
      "[thinning] changed param in1.weight shape: 24\n",
      "torch.Size([24])\n",
      "[thinning] changed param res2.conv1.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res2.conv1.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param in2.weight shape: 44\n",
      "torch.Size([44])\n",
      "[thinning] changed param deconv1.conv2d.bias shape: 44\n",
      "torch.Size([44])\n",
      "[thinning] changed param in2.bias shape: 44\n",
      "torch.Size([44])\n",
      "[thinning] changed param res1.in2.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param conv3.conv2d.weight shape: 44\n",
      "torch.Size([128, 44, 3, 3])\n",
      "[thinning] changed param conv3.conv2d.weight shape: 88\n",
      "torch.Size([88, 44, 3, 3])\n",
      "[thinning] changed param res5.in1.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param deconv2.conv2d.bias shape: 24\n",
      "torch.Size([24])\n",
      "[thinning] changed param res4.in1.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param deconv2.conv2d.weight shape: 44\n",
      "torch.Size([32, 44, 3, 3])\n",
      "[thinning] changed param deconv2.conv2d.weight shape: 24\n",
      "torch.Size([24, 44, 3, 3])\n",
      "[thinning] changed param res3.in1.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res5.in2.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res3.conv2.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res3.conv2.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param res2.in2.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res1.conv2.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res1.conv2.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param res5.conv1.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res5.conv1.conv2d.weight shape: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param in5.bias shape: 24\n",
      "torch.Size([24])\n",
      "[thinning] changed param conv2.conv2d.weight shape: 24\n",
      "torch.Size([64, 24, 3, 3])\n",
      "[thinning] changed param conv2.conv2d.weight shape: 44\n",
      "torch.Size([44, 24, 3, 3])\n",
      "[thinning] changed param res4.conv1.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res2.conv2.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res2.conv2.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param res1.conv1.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param in3.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res1.conv2.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res5.in1.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res1.in1.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res5.conv2.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res5.conv2.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param res5.conv1.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param conv1.conv2d.weight shape: 24\n",
      "torch.Size([24, 3, 9, 9])\n",
      "[thinning] changed param deconv3.conv2d.weight shape: 24\n",
      "torch.Size([3, 24, 9, 9])\n",
      "[thinning] changed param res3.in2.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param deconv1.conv2d.weight shape: 88\n",
      "torch.Size([64, 88, 3, 3])\n",
      "[thinning] changed param deconv1.conv2d.weight shape: 44\n",
      "torch.Size([44, 88, 3, 3])\n",
      "[thinning] changed param in3.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param in5.weight shape: 24\n",
      "torch.Size([24])\n",
      "[thinning] changed param res2.conv2.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res4.conv2.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res2.in1.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res4.conv1.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res4.conv1.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param res3.conv2.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res4.conv2.conv2d.weight shape: 88\n",
      "torch.Size([128, 88, 3, 3])\n",
      "[thinning] changed param res4.conv2.conv2d.weight shape: 88\n",
      "torch.Size([88, 88, 3, 3])\n",
      "[thinning] changed param res1.in2.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param conv2.conv2d.bias shape: 44\n",
      "torch.Size([44])\n",
      "[thinning] changed param res2.in2.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res2.conv1.conv2d.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res1.in1.bias shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res3.in1.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res4.in2.weight shape: 88\n",
      "torch.Size([88])\n",
      "[thinning] changed param res3.in2.weight shape: 88\n",
      "torch.Size([88])\n",
      "Created, applied and saved a thinning recipe\n",
      "Masking parameter conv1.conv2d.weight\n",
      "No mask for parameter conv1.conv2d.bias\n",
      "No mask for parameter in1.weight\n",
      "No mask for parameter in1.bias\n",
      "Masking parameter conv2.conv2d.weight\n",
      "No mask for parameter conv2.conv2d.bias\n",
      "No mask for parameter in2.weight\n",
      "No mask for parameter in2.bias\n",
      "Masking parameter conv3.conv2d.weight\n",
      "No mask for parameter conv3.conv2d.bias\n",
      "No mask for parameter in3.weight\n",
      "No mask for parameter in3.bias\n",
      "Masking parameter res1.conv1.conv2d.weight\n",
      "No mask for parameter res1.conv1.conv2d.bias\n",
      "No mask for parameter res1.in1.weight\n",
      "No mask for parameter res1.in1.bias\n",
      "Masking parameter res1.conv2.conv2d.weight\n",
      "No mask for parameter res1.conv2.conv2d.bias\n",
      "No mask for parameter res1.in2.weight\n",
      "No mask for parameter res1.in2.bias\n",
      "Masking parameter res2.conv1.conv2d.weight\n",
      "No mask for parameter res2.conv1.conv2d.bias\n",
      "No mask for parameter res2.in1.weight\n",
      "No mask for parameter res2.in1.bias\n",
      "Masking parameter res2.conv2.conv2d.weight\n",
      "No mask for parameter res2.conv2.conv2d.bias\n",
      "No mask for parameter res2.in2.weight\n",
      "No mask for parameter res2.in2.bias\n",
      "Masking parameter res3.conv1.conv2d.weight\n",
      "No mask for parameter res3.conv1.conv2d.bias\n",
      "No mask for parameter res3.in1.weight\n",
      "No mask for parameter res3.in1.bias\n",
      "Masking parameter res3.conv2.conv2d.weight\n",
      "No mask for parameter res3.conv2.conv2d.bias\n",
      "No mask for parameter res3.in2.weight\n",
      "No mask for parameter res3.in2.bias\n",
      "Masking parameter res4.conv1.conv2d.weight\n",
      "No mask for parameter res4.conv1.conv2d.bias\n",
      "No mask for parameter res4.in1.weight\n",
      "No mask for parameter res4.in1.bias\n",
      "Masking parameter res4.conv2.conv2d.weight\n",
      "No mask for parameter res4.conv2.conv2d.bias\n",
      "No mask for parameter res4.in2.weight\n",
      "No mask for parameter res4.in2.bias\n",
      "Masking parameter res5.conv1.conv2d.weight\n",
      "No mask for parameter res5.conv1.conv2d.bias\n",
      "No mask for parameter res5.in1.weight\n",
      "No mask for parameter res5.in1.bias\n",
      "Masking parameter res5.conv2.conv2d.weight\n",
      "No mask for parameter res5.conv2.conv2d.bias\n",
      "No mask for parameter res5.in2.weight\n",
      "No mask for parameter res5.in2.bias\n",
      "Masking parameter deconv1.conv2d.weight\n",
      "No mask for parameter deconv1.conv2d.bias\n",
      "No mask for parameter in4.weight\n",
      "No mask for parameter in4.bias\n",
      "Masking parameter deconv2.conv2d.weight\n",
      "No mask for parameter deconv2.conv2d.bias\n",
      "No mask for parameter in5.weight\n",
      "No mask for parameter in5.bias\n",
      "No mask for parameter deconv3.conv2d.weight\n",
      "No mask for parameter deconv3.conv2d.bias\n",
      "Parameter conv1.conv2d.weight does not maintain double copies\n",
      "No mask for parameter conv1.conv2d.bias\n",
      "No mask for parameter in1.weight\n",
      "No mask for parameter in1.bias\n",
      "Parameter conv2.conv2d.weight does not maintain double copies\n",
      "No mask for parameter conv2.conv2d.bias\n",
      "No mask for parameter in2.weight\n",
      "No mask for parameter in2.bias\n",
      "Parameter conv3.conv2d.weight does not maintain double copies\n",
      "No mask for parameter conv3.conv2d.bias\n",
      "No mask for parameter in3.weight\n",
      "No mask for parameter in3.bias\n",
      "Parameter res1.conv1.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res1.conv1.conv2d.bias\n",
      "No mask for parameter res1.in1.weight\n",
      "No mask for parameter res1.in1.bias\n",
      "Parameter res1.conv2.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res1.conv2.conv2d.bias\n",
      "No mask for parameter res1.in2.weight\n",
      "No mask for parameter res1.in2.bias\n",
      "Parameter res2.conv1.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res2.conv1.conv2d.bias\n",
      "No mask for parameter res2.in1.weight\n",
      "No mask for parameter res2.in1.bias\n",
      "Parameter res2.conv2.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res2.conv2.conv2d.bias\n",
      "No mask for parameter res2.in2.weight\n",
      "No mask for parameter res2.in2.bias\n",
      "Parameter res3.conv1.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res3.conv1.conv2d.bias\n",
      "No mask for parameter res3.in1.weight\n",
      "No mask for parameter res3.in1.bias\n",
      "Parameter res3.conv2.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res3.conv2.conv2d.bias\n",
      "No mask for parameter res3.in2.weight\n",
      "No mask for parameter res3.in2.bias\n",
      "Parameter res4.conv1.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res4.conv1.conv2d.bias\n",
      "No mask for parameter res4.in1.weight\n",
      "No mask for parameter res4.in1.bias\n",
      "Parameter res4.conv2.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res4.conv2.conv2d.bias\n",
      "No mask for parameter res4.in2.weight\n",
      "No mask for parameter res4.in2.bias\n",
      "Parameter res5.conv1.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res5.conv1.conv2d.bias\n",
      "No mask for parameter res5.in1.weight\n",
      "No mask for parameter res5.in1.bias\n",
      "Parameter res5.conv2.conv2d.weight does not maintain double copies\n",
      "No mask for parameter res5.conv2.conv2d.bias\n",
      "No mask for parameter res5.in2.weight\n",
      "No mask for parameter res5.in2.bias\n",
      "Parameter deconv1.conv2d.weight does not maintain double copies\n",
      "No mask for parameter deconv1.conv2d.bias\n",
      "No mask for parameter in4.weight\n",
      "No mask for parameter in4.bias\n",
      "Parameter deconv2.conv2d.weight does not maintain double copies\n",
      "No mask for parameter deconv2.conv2d.bias\n",
      "No mask for parameter in5.weight\n",
      "No mask for parameter in5.bias\n",
      "No mask for parameter deconv3.conv2d.weight\n",
      "No mask for parameter deconv3.conv2d.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "check_pytorch_version()\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "msglogger = apputils.config_pylogger(os.path.join(script_dir, 'logging.conf'), args.name, args.output_dir)\n",
    "\n",
    "# Log various details about the execution environment.  It is sometimes useful\n",
    "# to refer to past experiment executions and this information may be useful.\n",
    "apputils.log_execution_env_state(sys.argv, gitroot=module_path)\n",
    "msglogger.debug(\"Distiller: %s\", distiller.__version__)\n",
    "\n",
    "start_epoch = 0\n",
    "best_epochs = [distiller.MutableNamedTuple({'epoch': 0, 'loss': float(\"inf\"), 'sparsity': 0})\n",
    "               for i in range(args.num_best_scores)]\n",
    "\n",
    "if args.deterministic:\n",
    "    # Experiment reproducibility is sometimes important.  Pete Warden expounded about this\n",
    "    # in his blog: https://petewarden.com/2018/03/19/the-machine-learning-reproducibility-crisis/\n",
    "    # In Pytorch, support for deterministic execution is still a bit clunky.\n",
    "    if args.workers > 1:\n",
    "        msglogger.error('ERROR: Setting --deterministic requires setting --workers/-j to 0 or 1')\n",
    "        exit(1)\n",
    "        # Use a well-known seed, for repeatability of experiments\n",
    "        torch.manual_seed(0)\n",
    "        random.seed(0)\n",
    "        np.random.seed(0)\n",
    "        cudnn.deterministic = True\n",
    "    else:\n",
    "        # This issue: https://github.com/pytorch/pytorch/issues/3659\n",
    "        # Implies that cudnn.benchmark should respect cudnn.deterministic, but empirically we see that\n",
    "        # results are not re-produced when benchmark is set. So enabling only if deterministic mode disabled.\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "# if args.gpus is not None:\n",
    "#     try:\n",
    "#         args.gpus = [int(s) for s in args.gpus.split(',')]\n",
    "#     except ValueError:\n",
    "#         msglogger.error('ERROR: Argument --gpus must be a comma-separated list of integers only')\n",
    "#         exit(1)\n",
    "#     available_gpus = torch.cuda.device_count()\n",
    "#     for dev_id in args.gpus:\n",
    "#         if dev_id >= available_gpus:\n",
    "#             msglogger.error('ERROR: GPU device ID {0} requested, but only {1} devices available'\n",
    "#                             .format(dev_id, available_gpus))\n",
    "#             exit(1)\n",
    "#     # Set default device in case the first one on the list != 0\n",
    "#     torch.cuda.set_device(args.gpus[0])\n",
    "    \n",
    "# # Infer the dataset from the model name\n",
    "# args.dataset = 'cifar10' if 'cifar' in args.arch else 'imagenet'\n",
    "# args.num_classes = 10 if args.dataset == 'cifar10' else 1000\n",
    "\n",
    "if args.earlyexit_thresholds:\n",
    "    args.num_exits = len(args.earlyexit_thresholds) + 1\n",
    "    args.loss_exits = [0] * args.num_exits\n",
    "    args.losses_exits = []\n",
    "    args.exiterrors = []\n",
    "    \n",
    "# Create the model\n",
    "model = TransformerNet()\n",
    "if args.cuda:\n",
    "    device = torch.device(\"cuda:{}\".format(args.cuda-1))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "vgg = Vgg16(requires_grad=False).to(device)\n",
    "style_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.mul(255))\n",
    "])\n",
    "if args.pretrained:\n",
    "    resumed_state_dict = torch.load(args.pretrained)\n",
    "    # remove saved deprecated running_* keys in InstanceNorm from the checkpoint\n",
    "    for k in list(resumed_state_dict.keys()):\n",
    "        if re.search(r'in\\d+\\.running_(mean|var)$', k):\n",
    "            del resumed_state_dict[k]\n",
    "    model.load_state_dict(resumed_state_dict)\n",
    "    msglogger.info('Loaded pretrained model from %s\\n', args.pretrained)\n",
    "    \n",
    "\n",
    "compression_scheduler = None\n",
    "# Create a couple of logging backends.  TensorBoardLogger writes log files in a format\n",
    "# that can be read by Google's Tensor Board.  PythonLogger writes to the Python logger.\n",
    "tflogger = TensorBoardLogger(msglogger.logdir)\n",
    "pylogger = PythonLogger(msglogger)\n",
    "\n",
    "# capture thresholds for early-exit training\n",
    "if args.earlyexit_thresholds:\n",
    "    msglogger.info('=> using early-exit threshold values of %s', args.earlyexit_thresholds)\n",
    "\n",
    "# We can optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    model, compression_scheduler, start_epoch = apputils.load_checkpoint(\n",
    "        model, chkpt_file=args.resume)\n",
    "    \n",
    "# Define loss function (criterion) and optimizer\n",
    "optimizer = Adam(model.parameters(), args.lr)\n",
    "msglogger.info('Optimizer Type: %s', type(optimizer))\n",
    "msglogger.info('Optimizer Args: %s', optimizer.defaults)\n",
    "\n",
    "# This sample application can be invoked to produce various summary reports.\n",
    "# if args.summary:\n",
    "    # return summarize_model(model, args.dataset, which_summary=args.summary)\n",
    "    \n",
    "# Load the datasets: the dataset to load is inferred from the model name passed\n",
    "# in args.arch.  The default dataset is ImageNet, but if args.arch contains the\n",
    "# substring \"_cifar\", then cifar10 is used.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(args.image_size),\n",
    "    transforms.CenterCrop(args.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.mul(255))\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(args.dataset, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size)\n",
    "msglogger.info('Dataset sizes:\\n\\ttraining=%d\\n',\n",
    "               len(train_loader.sampler))\n",
    "\n",
    "activations_collectors = create_activation_stats_collectors(model, collection_phase=args.activation_stats)\n",
    "\n",
    "if args.compress:\n",
    "    # The main use-case for this sample application is CNN compression. Compression\n",
    "    # requires a compression schedule configuration file in YAML.\n",
    "    compression_scheduler = distiller.file_config(model, optimizer, args.compress)\n",
    "#     # Model is re-transferred to GPU in case parameters were added (e.g. PACTQuantizer)\n",
    "#     model.cuda()\n",
    "    model.to(device)\n",
    "else:\n",
    "    compression_scheduler = distiller.CompressionScheduler(model)\n",
    "        \n",
    "for epoch in range(start_epoch, start_epoch + args.epochs):\n",
    "    # This is the main training loop.\n",
    "    msglogger.info('\\n')\n",
    "    if compression_scheduler:\n",
    "        compression_scheduler.on_epoch_begin(epoch)\n",
    "        \n",
    "        # Train for one epoch\n",
    "        with collectors_context(activations_collectors[\"train\"]) as collectors:\n",
    "            train(train_loader, model, optimizer, vgg, epoch, compression_scheduler, [tflogger, pylogger],\n",
    "                  args.log_interval, args.style_image, args.style_size, args.content_weight, args.style_weight, device)\n",
    "            break\n",
    "            # distiller.log_weights_sparsity(model, epoch, loggers=[tflogger, pylogger])\n",
    "            # distiller.log_activation_statsitics(epoch, \"train\", loggers=[tflogger],\n",
    "            #                                     collector=collectors[\"sparsity\"])\n",
    "            if args.masks_sparsity:\n",
    "                msglogger.info(distiller.masks_sparsity_tbl_summary(model, compression_scheduler))\n",
    "                \n",
    "#         # evaluate on validation set\n",
    "#         with collectors_context(activations_collectors[\"valid\"]) as collectors:\n",
    "#             top1, top5, vloss = validate(train_loader, model, None, [pylogger], args, epoch)\n",
    "#             distiller.log_activation_statsitics(epoch, \"valid\", loggers=[tflogger],\n",
    "#                                                 collector=collectors[\"sparsity\"], device)\n",
    "#             save_collectors_data(collectors, msglogger.logdir)\n",
    "            \n",
    "#         if compression_scheduler:\n",
    "#             compression_scheduler.on_epoch_end(epoch, optimizer)\n",
    "\n",
    "#         # remember best top1 and save checkpoint\n",
    "#         is_best = vloss < best_epochs[0].loss\n",
    "#         if is_best:\n",
    "#             best_epochs[0].epoch = epoch\n",
    "#             best_epochs[0].loss = vloss\n",
    "#             best_epochs = sorted(best_epochs, key=lambda score: score.loss, reverse=True)\n",
    "#         for score in reversed(best_epochs):\n",
    "#             if score.loss > 0:\n",
    "#                 msglogger.info('==> Best Loss: %.3f on Epoch: %d', score.loss, score.epoch)\n",
    "#         apputils.save_checkpoint(epoch, None, model, optimizer, compression_scheduler,\n",
    "#                                  best_epochs[0].loss, is_best, args.name, msglogger.logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERALL_LOSS_KEY = 'Overall Loss'\n",
    "OBJECTIVE_LOSS_KEY = 'Objective Loss'\n",
    "\n",
    "def train(train_loader, model, optimizer, vgg, epoch, compression_scheduler, loggers,\n",
    "          log_interval, style_image, style_size, content_weight, style_weight, device):\n",
    "#     np.random.seed(args.seed)\n",
    "#     torch.manual_seed(args.seed)\n",
    "    \"\"\"Training loop for one epoch.\"\"\"\n",
    "    losses = OrderedDict([(OVERALL_LOSS_KEY, tnt.AverageValueMeter()),\n",
    "                          (OBJECTIVE_LOSS_KEY, tnt.AverageValueMeter())])\n",
    "   \n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    \n",
    "    total_samples = len(train_loader.sampler)\n",
    "    batch_size = train_loader.batch_size\n",
    "    steps_per_epoch = math.ceil(total_samples / batch_size)\n",
    "    msglogger.info('Training epoch: %d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "    \n",
    "    style = utils.load_image(style_image, size=style_size)\n",
    "    style = style_transform(style)\n",
    "    style = style.repeat(batch_size, 1, 1, 1).to(device)\n",
    "    \n",
    "    features_style = vgg(utils.normalize_batch(style))\n",
    "    gram_style = [utils.gram_matrix(y) for y in features_style]\n",
    "    \n",
    "    model.train()\n",
    "    agg_content_loss = 0.\n",
    "    agg_style_loss = 0.\n",
    "    count = 0\n",
    "    end = time.time()\n",
    "    for batch_id, (x, _) in enumerate(train_loader):\n",
    "        n_batch = len(x)\n",
    "        count += n_batch\n",
    "        \n",
    "        # Execute the forward phase, compute the output and measure loss\n",
    "        if compression_scheduler:\n",
    "            compression_scheduler.on_minibatch_begin(epoch, batch_id, steps_per_epoch, optimizer)\n",
    "\n",
    "        if batch_id == 10:\n",
    "            break\n",
    "        x = x.to(device)\n",
    "        y = model(x)\n",
    "\n",
    "        y = utils.normalize_batch(y)\n",
    "        x = utils.normalize_batch(x)\n",
    "\n",
    "        features_y = vgg(y)\n",
    "        features_x = vgg(x)\n",
    "\n",
    "        content_loss = content_weight * mse_loss(features_y.relu2_2, features_x.relu2_2)\n",
    "\n",
    "        style_loss = 0.\n",
    "        for ft_y, gm_s in zip(features_y, gram_style):\n",
    "            gm_y = utils.gram_matrix(ft_y)\n",
    "            style_loss += mse_loss(gm_y, gm_s[:n_batch, :, :])\n",
    "        style_loss *= style_weight\n",
    "\n",
    "        loss = content_loss + style_loss\n",
    "\n",
    "        losses[OBJECTIVE_LOSS_KEY].add(loss.item())\n",
    "        \n",
    "        if compression_scheduler:\n",
    "            # Before running the backward phase, we allow the scheduler to modify the loss\n",
    "            # (e.g. add regularization loss)\n",
    "            agg_loss = compression_scheduler.before_backward_pass(epoch, batch_id, steps_per_epoch, loss,\n",
    "                                                                  optimizer=optimizer, return_loss_components=True)\n",
    "            loss = agg_loss.overall_loss\n",
    "            losses[OVERALL_LOSS_KEY].add(loss.item())\n",
    "            for lc in agg_loss.loss_components:\n",
    "                if lc.name not in losses:\n",
    "                    losses[lc.name] = tnt.AverageValueMeter()\n",
    "                losses[lc.name].add(lc.value.item())\n",
    "        \n",
    "        # Compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(optimizer)\n",
    "        if compression_scheduler:\n",
    "            compression_scheduler.on_minibatch_end(epoch, batch_id, steps_per_epoch, optimizer)\n",
    "        break\n",
    "        \n",
    "        if batch_id == 10:\n",
    "            return\n",
    "        if (batch_id + 1) % log_interval == 0:\n",
    "            stats_dict = OrderedDict()\n",
    "            for loss_name, meter in losses.items():\n",
    "                stats_dict[loss_name] = meter.mean\n",
    "            # stats_dict.update(errs)\n",
    "            stats_dict['LR'] = optimizer.param_groups[0]['lr']\n",
    "            # stats_dict['Time'] = batch_time.mean\n",
    "            stats = ('Peformance/Training/', stats_dict)\n",
    "\n",
    "            params = model.named_parameters() if args.log_params_histograms else None\n",
    "            distiller.log_training_progress(stats,\n",
    "                                            params,\n",
    "                                            epoch, batch_id+1,\n",
    "                                            steps_per_epoch, log_interval,\n",
    "                                            loggers)\n",
    "            \n",
    "def validate(val_loader, model, criterion, loggers, args, epoch=-1):\n",
    "    \"\"\"Model validation\"\"\"\n",
    "    if epoch > -1:\n",
    "        msglogger.info('--- validate (epoch=%d)-----------', epoch)\n",
    "    else:\n",
    "        msglogger.info('--- validate ---------------------')\n",
    "    return _validate(val_loader, model, criterion, loggers, args, epoch)\n",
    "\n",
    "def _validate(data_loader, model, criterion, loggers, args, epoch=-1):\n",
    "    \"\"\"Execute the validation/test loop.\"\"\"\n",
    "    losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "    # classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, 5))\n",
    "\n",
    "    if args.earlyexit_thresholds:\n",
    "        # for Early Exit, we have a list of errors and losses for each of the exits.\n",
    "        args.exiterrors = []\n",
    "        args.losses_exits = []\n",
    "        for exitnum in range(args.num_exits):\n",
    "            # args.exiterrors.append(tnt.ClassErrorMeter(accuracy=True, topk=(1, 5)))\n",
    "            args.losses_exits.append(tnt.AverageValueMeter())\n",
    "        args.exit_taken = [0] * args.num_exits\n",
    "\n",
    "    batch_time = tnt.AverageValueMeter()\n",
    "    total_samples = len(data_loader.sampler)\n",
    "    batch_size = data_loader.batch_size\n",
    "    if args.display_confusion:\n",
    "        confusion = tnt.ConfusionMeter(args.num_classes)\n",
    "    total_steps = total_samples / batch_size\n",
    "    msglogger.info('%d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    steps_per_epoch = math.ceil(total_samples / batch_size)\n",
    "    msglogger.info('Training epoch: %d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "    \n",
    "    style = utils.load_image(args.style_image, size=args.style_size)\n",
    "    style = style_transform(style)\n",
    "    style = style.repeat(batch_size, 1, 1, 1).to(device)\n",
    "    \n",
    "    features_style = vgg(utils.normalize_batch(style))\n",
    "    gram_style = [utils.gram_matrix(y) for y in features_style]\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for validation_step, (x, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():            \n",
    "            if not args.earlyexit_thresholds:\n",
    "                if validation_step == 10:\n",
    "                    break\n",
    "                n_batch = len(x)\n",
    "                x = x.to(device)\n",
    "                y = model(x)\n",
    "\n",
    "                y = utils.normalize_batch(y)\n",
    "                x = utils.normalize_batch(x)\n",
    "\n",
    "                features_y = vgg(y)\n",
    "                features_x = vgg(x)\n",
    "\n",
    "                content_loss = args.content_weight * mse_loss(features_y.relu2_2, features_x.relu2_2)\n",
    "\n",
    "                style_loss = 0.\n",
    "                for ft_y, gm_s in zip(features_y, gram_style):\n",
    "                    gm_y = utils.gram_matrix(ft_y)\n",
    "                    style_loss += mse_loss(gm_y, gm_s[:n_batch, :, :])\n",
    "                style_loss *= args.style_weight\n",
    "\n",
    "                loss = content_loss + style_loss\n",
    "                \n",
    "                losses['objective_loss'].add(loss.item())\n",
    "                # classerr.add(output.data, target)\n",
    "                if args.display_confusion:\n",
    "                    confusion.add(output.data, target)\n",
    "            else:\n",
    "                earlyexit_validate_loss(output, target, criterion, args)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.add(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            steps_completed = (validation_step+1)\n",
    "            if steps_completed == 10:\n",
    "                break\n",
    "            if steps_completed % args.log_interval == 0:\n",
    "                if not args.earlyexit_thresholds:\n",
    "                    stats = ('',\n",
    "                             OrderedDict([('Loss', losses['objective_loss'].mean)]))\n",
    "#                             OrderedDict([('Loss', losses['objective_loss'].mean),\n",
    "#                                          ('Top1', classerr.value(1)),\n",
    "#                                          ('Top5', classerr.value(5))]))\n",
    "                else:\n",
    "                    stats_dict = OrderedDict()\n",
    "                    stats_dict['Test'] = validation_step\n",
    "                    for exitnum in range(args.num_exits):\n",
    "                        la_string = 'LossAvg' + str(exitnum)\n",
    "                        stats_dict[la_string] = args.losses_exits[exitnum].mean\n",
    "                        # Because of the nature of ClassErrorMeter, if an exit is never taken during the batch,\n",
    "                        # then accessing the value(k) will cause a divide by zero. So we'll build the OrderedDict\n",
    "                        # accordingly and we will not print for an exit error when that exit is never taken.\n",
    "                        if args.exit_taken[exitnum]:\n",
    "                            t1 = 'Top1_exit' + str(exitnum)\n",
    "                            t5 = 'Top5_exit' + str(exitnum)\n",
    "                            stats_dict[t1] = args.exiterrors[exitnum].value(1)\n",
    "                            stats_dict[t5] = args.exiterrors[exitnum].value(5)\n",
    "                    stats = ('Performance/Validation/', stats_dict)\n",
    "\n",
    "                distiller.log_training_progress(stats, None, epoch, steps_completed,\n",
    "                                                total_steps, args.log_interval, loggers)\n",
    "    if not args.earlyexit_thresholds:\n",
    "        msglogger.info('==> Top1: %.3f    Top5: %.3f    Loss: %.3f\\n',\n",
    "                       0, 0, losses['objective_loss'].mean)\n",
    "\n",
    "        if args.display_confusion:\n",
    "            msglogger.info('==> Confusion:\\n%s\\n', str(confusion.value()))\n",
    "        return 0, 0, losses['objective_loss'].mean\n",
    "    else:\n",
    "        total_top1, total_top5, losses_exits_stats = earlyexit_validate_stats(args)\n",
    "        return total_top1, total_top5, losses_exits_stats[args.num_exits-1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
