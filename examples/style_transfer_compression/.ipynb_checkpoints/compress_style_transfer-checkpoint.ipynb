{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Gradual Pruning Schedule\n",
    "\n",
    "Michael Zhu and Suyog Gupta, [\"To prune, or not to prune: exploring the efficacy of pruning for model compression\"](https://arxiv.org/pdf/1710.01878), 2017 NIPS Workshop on Machine Learning of Phones and other Consumer Devices<br>\n",
    "<br>\n",
    "After completing sensitivity analysis, decide on your pruning schedule.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Implementation of the gradual sparsity function](#Implementation-of-the-gradual-sparsity-function)\n",
    "2. [Visualize pruning schedule](#Visualize-pruning-schedule)\n",
    "3. [References](#References)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import traceback\n",
    "from collections import OrderedDict, defaultdict\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchnet.meter as tnt\n",
    "# script_dir = os.path.dirname(__file__)\n",
    "script_dir = os.path.abspath('/host/model_compression/distiller/examples/style_transfer_compression')\n",
    "module_path = os.path.abspath(os.path.join(script_dir, '..', '..'))\n",
    "try:\n",
    "    import distiller\n",
    "except ImportError:\n",
    "    sys.path.append(module_path)\n",
    "    import distiller\n",
    "import apputils\n",
    "from distiller.data_loggers import *\n",
    "import distiller.quantization as quantization\n",
    "from models import ALL_MODEL_NAMES, create_model\n",
    "\n",
    "sys.path.append('/host/frameworks/examples/fast_neural_style/neural_style')\n",
    "from utils import *\n",
    "from neural_style import *\n",
    "\n",
    "# Logger handle\n",
    "msglogger = None\n",
    "\n",
    "\n",
    "def float_range(val_str):\n",
    "    val = float(val_str)\n",
    "    if val < 0 or val >= 1:\n",
    "        raise argparse.ArgumentTypeError('Must be >= 0 and < 1 (received {0})'.format(val_str))\n",
    "    return val\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Distiller image classification model compression')\n",
    "parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',\n",
    "                    choices=ALL_MODEL_NAMES,\n",
    "                    help='model architecture: ' +\n",
    "                    ' | '.join(ALL_MODEL_NAMES) +\n",
    "                    ' (default: resnet18)')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 256)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model')\n",
    "parser.add_argument('--act-stats', dest='activation_stats', choices=[\"train\", \"valid\", \"test\"], default=None,\n",
    "                    help='collect activation statistics (WARNING: this slows down training)')\n",
    "parser.add_argument('--masks-sparsity', dest='masks_sparsity', action='store_true', default=False,\n",
    "                    help='print masks sparsity table at end of each epoch')\n",
    "parser.add_argument('--param-hist', dest='log_params_histograms', action='store_true', default=False,\n",
    "                    help='log the paramter tensors histograms to file (WARNING: this can use significant disk space)')\n",
    "SUMMARY_CHOICES = ['sparsity', 'compute', 'model', 'modules', 'png', 'png_w_params', 'onnx']\n",
    "parser.add_argument('--summary', type=str, choices=SUMMARY_CHOICES,\n",
    "                    help='print a summary of the model, and exit - options: ' +\n",
    "                    ' | '.join(SUMMARY_CHOICES))\n",
    "parser.add_argument('--compress', dest='compress', type=str, nargs='?', action='store',\n",
    "                    help='configuration file for pruning the model (default is to use hard-coded schedule)')\n",
    "parser.add_argument('--sense', dest='sensitivity', choices=['element', 'filter', 'channel'],\n",
    "                    help='test the sensitivity of layers to pruning')\n",
    "parser.add_argument('--extras', default=None, type=str,\n",
    "                    help='file with extra configuration information')\n",
    "parser.add_argument('--deterministic', '--det', action='store_true',\n",
    "                    help='Ensure deterministic execution for re-producible results.')\n",
    "parser.add_argument('--gpus', metavar='DEV_ID', default=None,\n",
    "                    help='Comma-separated list of GPU device IDs to be used (default is to use all available devices)')\n",
    "parser.add_argument('--name', '-n', metavar='NAME', default=None, help='Experiment name')\n",
    "parser.add_argument('--out-dir', '-o', dest='output_dir', default='logs', help='Path to dump logs and checkpoints')\n",
    "parser.add_argument('--validation-size', '--vs', type=float_range, default=0.1,\n",
    "                    help='Portion of training dataset to set aside for validation')\n",
    "parser.add_argument('--adc', dest='ADC', action='store_true', help='temp HACK')\n",
    "parser.add_argument('--adc-params', dest='ADC_params', default=None, help='temp HACK')\n",
    "parser.add_argument('--confusion', dest='display_confusion', default=False, action='store_true',\n",
    "                    help='Display the confusion matrix')\n",
    "parser.add_argument('--earlyexit_lossweights', type=float, nargs='*', dest='earlyexit_lossweights', default=None,\n",
    "                    help='List of loss weights for early exits (e.g. --lossweights 0.1 0.3)')\n",
    "parser.add_argument('--earlyexit_thresholds', type=float, nargs='*', dest='earlyexit_thresholds', default=None,\n",
    "                    help='List of EarlyExit thresholds (e.g. --earlyexit 1.2 0.9)')\n",
    "parser.add_argument('--num-best-scores', dest='num_best_scores', default=1, type=int,\n",
    "                    help='number of best scores to track and report (default: 1)')\n",
    "parser.add_argument('--load-serialized', dest='load_serialized', action='store_true', default=False,\n",
    "                    help='Load a model without DataParallel wrapping it')\n",
    "                    \n",
    "quant_group = parser.add_argument_group('Arguments controlling quantization at evaluation time'\n",
    "                                        '(\"post-training quantization)')\n",
    "quant_group.add_argument('--quantize-eval', '--qe', action='store_true',\n",
    "                         help='Apply linear-symmetric quantization to model before evaluation. Applicable only if'\n",
    "                              '--evaluate is also set')\n",
    "quant_group.add_argument('--qe-bits-acts', '--qeba', type=int, default=8, metavar='NUM_BITS',\n",
    "                         help='Number of bits for quantization of activations')\n",
    "quant_group.add_argument('--qe-bits-wts', '--qebw', type=int, default=8, metavar='NUM_BITS',\n",
    "                         help='Number of bits for quantization of weights')\n",
    "quant_group.add_argument('--qe-bits-accum', type=int, default=32, metavar='NUM_BITS',\n",
    "                         help='Number of bits for quantization of the accumulator')\n",
    "quant_group.add_argument('--qe-clip-acts', '--qeca', action='store_true',\n",
    "                         help='Enable clipping of activations using max-abs-value averaging over batch')\n",
    "quant_group.add_argument('--qe-no-clip-layers', '--qencl', type=str, nargs='+', metavar='LAYER_NAME', default=[],\n",
    "                         help='List of fully-qualified layer names for which not to clip activations. Applicable'\n",
    "                              'only if --qe-clip-acts is also set')\n",
    "\n",
    "distiller.knowledge_distillation.add_distillation_args(parser, ALL_MODEL_NAMES, True)\n",
    "\n",
    "def check_pytorch_version():\n",
    "    if torch.__version__ < '0.4.0':\n",
    "        print(\"\\nNOTICE:\")\n",
    "        print(\"The Distiller \\'master\\' branch now requires at least PyTorch version 0.4.0 due to \"\n",
    "              \"PyTorch API changes which are not backward-compatible.\\n\"\n",
    "              \"Please install PyTorch 0.4.0 or its derivative.\\n\"\n",
    "              \"If you are using a virtual environment, do not forget to update it:\\n\"\n",
    "              \"  1. Deactivate the old environment\\n\"\n",
    "              \"  2. Install the new environment\\n\"\n",
    "              \"  3. Activate the new environment\")\n",
    "        exit(1)\n",
    "    else:\n",
    "        print(\"torch version: \" + torch.__version__)\n",
    "        \n",
    "def create_activation_stats_collectors(model, collection_phase):\n",
    "    \"\"\"Create objects that collect activation statistics.\n",
    "\n",
    "    This is a utility function that creates two collectors:\n",
    "    1. Fine-grade sparsity levels of the activations\n",
    "    2. L1-magnitude of each of the activation channels\n",
    "\n",
    "    Args:\n",
    "        model - the model on which we want to collect statistics\n",
    "        phase - the statistics collection phase which is either \"train\" (for training),\n",
    "                or \"valid\" (for validation)\n",
    "\n",
    "    WARNING! Enabling activation statsitics collection will significantly slow down training!\n",
    "    \"\"\"\n",
    "    class missingdict(dict):\n",
    "        \"\"\"This is a little trick to prevent KeyError\"\"\"\n",
    "        def __missing__(self, key):\n",
    "            return None  # note, does *not* set self[key] - we don't want defaultdict's behavior\n",
    "\n",
    "    distiller.utils.assign_layer_fq_names(model)\n",
    "\n",
    "    activations_collectors = {\"train\": missingdict(), \"valid\": missingdict(), \"test\": missingdict()}\n",
    "    if collection_phase is None:\n",
    "        return activations_collectors\n",
    "    collectors = missingdict()\n",
    "    collectors[\"sparsity\"] = SummaryActivationStatsCollector(model, \"sparsity\", distiller.utils.sparsity)\n",
    "    collectors[\"l1_channels\"] = SummaryActivationStatsCollector(model, \"l1_channels\",\n",
    "                                                                distiller.utils.activation_channels_l1)\n",
    "    collectors[\"apoz_channels\"] = SummaryActivationStatsCollector(model, \"apoz_channels\",\n",
    "                                                                  distiller.utils.activation_channels_apoz)\n",
    "    collectors[\"records\"] = RecordsActivationStatsCollector(model, classes=[torch.nn.Conv2d])\n",
    "    activations_collectors[collection_phase] = collectors\n",
    "    return activations_collectors       \n",
    "        \n",
    "def save_collectors_data(collectors, directory):\n",
    "    \"\"\"Utility function that saves all activation statistics to Excel workbooks\n",
    "    \"\"\"\n",
    "    for name, collector in collectors.items():\n",
    "        collector.to_xlsx(os.path.join(directory, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "args = Object()\n",
    "args.dataset = '/host/dataset/COCO'\n",
    "args.epochs = 4\n",
    "args.batch_size = 2\n",
    "args.output_dir = './logs'\n",
    "args.name = None\n",
    "args.deterministic = False\n",
    "args.cuda = 1\n",
    "args.earlyexit_thresholds = None\n",
    "args.resume = None\n",
    "args.lr = 1e-4\n",
    "args.style_size = None\n",
    "args.log_interval = 2\n",
    "args.log_params_histograms = False\n",
    "args.activation_stats = False\n",
    "args.image_size = 256\n",
    "args.pretrained = './pretrained/mosaic.pth'\n",
    "args.content_weight = 1e5\n",
    "args.style_weight = 1e10\n",
    "args.style_image = \"./mosaic.jpg\"\n",
    "args.compress = './original_filter_rank.yaml'\n",
    "args.num_best_scores = 1\n",
    "args.masks_sparsity = False\n",
    "args.display_confusion = False\n",
    "print(args.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776\n",
      "torch.Size([32, 3, 9, 9])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.numel(compression_scheduler.zeros_mask_dict['conv1.conv2d.weight'].mask))\n",
    "print(compression_scheduler.zeros_mask_dict['conv1.conv2d.weight'].mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log file for this run: /host/model_compression/distiller/examples/style_transfer_compression/logs/2018.11.09-104545/2018.11.09-104545.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model from ./pretrained/mosaic.pth\n",
      "\n",
      "Optimizer Type: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer Args: {'weight_decay': 0, 'amsgrad': False, 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "Logging to TensorBoard - remember to execute the server:\n",
      "> tensorboard --logdir='./logs'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "\ttraining=82783\n",
      "\n",
      "Reading compression schedule from: ./original_filter_rank.yaml\n",
      "\n",
      "\n",
      "L1RankedStructureParameterPruner - param: conv1.conv2d.weight pruned=0.594 goal=0.600 (19/32)\n",
      "L1RankedStructureParameterPruner - param: conv2.conv2d.weight pruned=0.594 goal=0.600 (38/64)\n",
      "L1RankedStructureParameterPruner - param: conv3.conv2d.weight pruned=0.594 goal=0.600 (76/128)\n",
      "L1RankedStructureParameterPruner - param: res1.conv1.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res1.conv2.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res2.conv1.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res2.conv2.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res3.conv1.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res3.conv2.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res4.conv1.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res4.conv2.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res5.conv1.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: res5.conv2.conv2d.weight pruned=0.500 goal=0.500 (64/128)\n",
      "L1RankedStructureParameterPruner - param: deconv1.conv2d.weight pruned=0.594 goal=0.600 (38/64)\n",
      "L1RankedStructureParameterPruner - param: deconv2.conv2d.weight pruned=0.594 goal=0.600 (19/32)\n",
      "L1RankedStructureParameterPruner - param: deconv3.conv2d.weight pruned=0.333 goal=0.600 (1/3)\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Epoch: [0][    2/41392]    Overall Loss 865634016.000000    Objective Loss 865634016.000000    LR 0.000100    \n",
      "Epoch: [0][    4/41392]    Overall Loss 857218448.000000    Objective Loss 857218448.000000    LR 0.000100    \n",
      "Epoch: [0][    6/41392]    Overall Loss 852345045.333333    Objective Loss 852345045.333333    LR 0.000100    \n",
      "Epoch: [0][    8/41392]    Overall Loss 846499688.000000    Objective Loss 846499688.000000    LR 0.000100    \n",
      "Epoch: [0][   10/41392]    Overall Loss 840594400.000000    Objective Loss 840594400.000000    LR 0.000100    \n",
      "\n",
      "Parameters:\n",
      "+----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
      "|    | Name                     | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |\n",
      "|----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|\n",
      "|  0 | conv1.conv2d.weight      | (32, 3, 9, 9)    |          7776 |           3159 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.11150 |  0.00180 |    0.04920 |\n",
      "|  1 | conv2.conv2d.weight      | (64, 32, 3, 3)   |         18432 |           7488 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.13929 | -0.00496 |    0.06527 |\n",
      "|  2 | conv3.conv2d.weight      | (128, 64, 3, 3)  |         73728 |          29952 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.12642 | -0.00161 |    0.06131 |\n",
      "|  3 | res1.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.13938 | -0.01523 |    0.07556 |\n",
      "|  4 | res1.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12740 |  0.00192 |    0.06980 |\n",
      "|  5 | res2.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.13094 | -0.00501 |    0.07279 |\n",
      "|  6 | res2.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12623 |  0.00098 |    0.06929 |\n",
      "|  7 | res3.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12710 | -0.00389 |    0.07036 |\n",
      "|  8 | res3.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12377 |  0.00223 |    0.06757 |\n",
      "|  9 | res4.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12089 | -0.00159 |    0.06682 |\n",
      "| 10 | res4.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11599 |  0.00133 |    0.06358 |\n",
      "| 11 | res5.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11606 | -0.00210 |    0.06302 |\n",
      "| 12 | res5.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11013 |  0.00059 |    0.05926 |\n",
      "| 13 | deconv1.conv2d.weight    | (64, 128, 3, 3)  |         73728 |          29952 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.09866 |  0.00004 |    0.04831 |\n",
      "| 14 | deconv2.conv2d.weight    | (32, 64, 3, 3)   |         18432 |           7488 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.08379 | -0.00273 |    0.04089 |\n",
      "| 15 | deconv3.conv2d.weight    | (3, 32, 9, 9)    |          7776 |           5184 |          0 |          0 |  0.00000 | 33.33333 | 33.33333 |   33.33333 | 0.24412 |  0.03738 |    0.14094 |\n",
      "| 16 | Total sparsity:          | -                |       1674432 |         820503 |          0 |          0 |  0.00000 |  0.00000 |  0.00000 |   50.99813 | 0.00000 |  0.00000 |    0.00000 |\n",
      "+----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
      "Total sparsity: 51.00\n",
      "\n",
      "--- validate (epoch=0)-----------\n",
      "82783 samples (2 per mini-batch)\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Epoch: [0][    2/41391]    Loss 802074656.000000    \n",
      "Epoch: [0][    4/41391]    Loss 801135648.000000    \n",
      "Epoch: [0][    6/41391]    Loss 802159221.333333    \n",
      "Epoch: [0][    8/41391]    Loss 802434232.000000    \n",
      "==> Top1: 0.000    Top5: 0.000    Loss: 802292588.800\n",
      "\n",
      "==> Best Loss: 802292588.800 on Epoch: 0\n",
      "Saving checkpoint to: ./logs/2018.11.09-104545/checkpoint.pth.tar\n",
      "\n",
      "\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Epoch: [1][    2/41392]    Overall Loss 799612704.000000    Objective Loss 799612704.000000    LR 0.000100    \n",
      "Epoch: [1][    4/41392]    Overall Loss 794021888.000000    Objective Loss 794021888.000000    LR 0.000100    \n",
      "Epoch: [1][    6/41392]    Overall Loss 790243722.666667    Objective Loss 790243722.666667    LR 0.000100    \n",
      "Epoch: [1][    8/41392]    Overall Loss 785693184.000000    Objective Loss 785693184.000000    LR 0.000100    \n",
      "Epoch: [1][   10/41392]    Overall Loss 780447372.800000    Objective Loss 780447372.800000    LR 0.000100    \n",
      "\n",
      "Parameters:\n",
      "+----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
      "|    | Name                     | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |\n",
      "|----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|\n",
      "|  0 | conv1.conv2d.weight      | (32, 3, 9, 9)    |          7776 |           3159 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.11150 |  0.00183 |    0.04921 |\n",
      "|  1 | conv2.conv2d.weight      | (64, 32, 3, 3)   |         18432 |           7488 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.13929 | -0.00497 |    0.06527 |\n",
      "|  2 | conv3.conv2d.weight      | (128, 64, 3, 3)  |         73728 |          29952 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.12642 | -0.00161 |    0.06131 |\n",
      "|  3 | res1.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.13937 | -0.01523 |    0.07556 |\n",
      "|  4 | res1.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12740 |  0.00192 |    0.06980 |\n",
      "|  5 | res2.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.13094 | -0.00501 |    0.07279 |\n",
      "|  6 | res2.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12623 |  0.00099 |    0.06929 |\n",
      "|  7 | res3.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12710 | -0.00389 |    0.07036 |\n",
      "|  8 | res3.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12377 |  0.00223 |    0.06758 |\n",
      "|  9 | res4.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12090 | -0.00159 |    0.06682 |\n",
      "| 10 | res4.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11599 |  0.00133 |    0.06358 |\n",
      "| 11 | res5.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11606 | -0.00210 |    0.06302 |\n",
      "| 12 | res5.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11013 |  0.00059 |    0.05926 |\n",
      "| 13 | deconv1.conv2d.weight    | (64, 128, 3, 3)  |         73728 |          29952 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.09866 |  0.00004 |    0.04831 |\n",
      "| 14 | deconv2.conv2d.weight    | (32, 64, 3, 3)   |         18432 |           7488 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.08379 | -0.00274 |    0.04089 |\n",
      "| 15 | deconv3.conv2d.weight    | (3, 32, 9, 9)    |          7776 |           5184 |          0 |          0 |  0.00000 | 33.33333 | 33.33333 |   33.33333 | 0.24404 |  0.03682 |    0.14081 |\n",
      "| 16 | Total sparsity:          | -                |       1674432 |         820503 |          0 |          0 |  0.00000 |  0.00000 |  0.00000 |   50.99813 | 0.00000 |  0.00000 |    0.00000 |\n",
      "+----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total sparsity: 51.00\n",
      "\n",
      "--- validate (epoch=1)-----------\n",
      "82783 samples (2 per mini-batch)\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Epoch: [1][    2/41391]    Loss 752242496.000000    \n",
      "Epoch: [1][    4/41391]    Loss 751193280.000000    \n",
      "Epoch: [1][    6/41391]    Loss 751968480.000000    \n",
      "Epoch: [1][    8/41391]    Loss 751815992.000000    \n",
      "==> Top1: 0.000    Top5: 0.000    Loss: 750945369.600\n",
      "\n",
      "==> Best Loss: 750945369.600 on Epoch: 1\n",
      "Saving checkpoint to: ./logs/2018.11.09-104545/checkpoint.pth.tar\n",
      "\n",
      "\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Epoch: [2][    2/41392]    Overall Loss 752030176.000000    Objective Loss 752030176.000000    LR 0.000010    \n",
      "Epoch: [2][    4/41392]    Overall Loss 750559936.000000    Objective Loss 750559936.000000    LR 0.000010    \n",
      "Epoch: [2][    6/41392]    Overall Loss 750918869.333333    Objective Loss 750918869.333333    LR 0.000010    \n",
      "Epoch: [2][    8/41392]    Overall Loss 750325472.000000    Objective Loss 750325472.000000    LR 0.000010    \n",
      "Epoch: [2][   10/41392]    Overall Loss 748996486.400000    Objective Loss 748996486.400000    LR 0.000010    \n",
      "\n",
      "Parameters:\n",
      "+----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
      "|    | Name                     | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |\n",
      "|----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|\n",
      "|  0 | conv1.conv2d.weight      | (32, 3, 9, 9)    |          7776 |           3159 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.11150 |  0.00184 |    0.04921 |\n",
      "|  1 | conv2.conv2d.weight      | (64, 32, 3, 3)   |         18432 |           7488 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.13929 | -0.00497 |    0.06527 |\n",
      "|  2 | conv3.conv2d.weight      | (128, 64, 3, 3)  |         73728 |          29952 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.12642 | -0.00161 |    0.06131 |\n",
      "|  3 | res1.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.13937 | -0.01523 |    0.07556 |\n",
      "|  4 | res1.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12740 |  0.00191 |    0.06980 |\n",
      "|  5 | res2.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.13094 | -0.00501 |    0.07279 |\n",
      "|  6 | res2.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12623 |  0.00099 |    0.06929 |\n",
      "|  7 | res3.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12710 | -0.00389 |    0.07036 |\n",
      "|  8 | res3.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12377 |  0.00223 |    0.06758 |\n",
      "|  9 | res4.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12090 | -0.00159 |    0.06682 |\n",
      "| 10 | res4.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11599 |  0.00133 |    0.06358 |\n",
      "| 11 | res5.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11606 | -0.00210 |    0.06302 |\n",
      "| 12 | res5.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11013 |  0.00059 |    0.05926 |\n",
      "| 13 | deconv1.conv2d.weight    | (64, 128, 3, 3)  |         73728 |          29952 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.09866 |  0.00004 |    0.04831 |\n",
      "| 14 | deconv2.conv2d.weight    | (32, 64, 3, 3)   |         18432 |           7488 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.08379 | -0.00274 |    0.04089 |\n",
      "| 15 | deconv3.conv2d.weight    | (3, 32, 9, 9)    |          7776 |           5184 |          0 |          0 |  0.00000 | 33.33333 | 33.33333 |   33.33333 | 0.24403 |  0.03676 |    0.14080 |\n",
      "| 16 | Total sparsity:          | -                |       1674432 |         820503 |          0 |          0 |  0.00000 |  0.00000 |  0.00000 |   50.99813 | 0.00000 |  0.00000 |    0.00000 |\n",
      "+----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
      "Total sparsity: 51.00\n",
      "\n",
      "--- validate (epoch=2)-----------\n",
      "82783 samples (2 per mini-batch)\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Epoch: [2][    2/41391]    Loss 747653600.000000    \n",
      "Epoch: [2][    4/41391]    Loss 746552240.000000    \n",
      "Epoch: [2][    6/41391]    Loss 747328789.333333    \n",
      "Epoch: [2][    8/41391]    Loss 747130800.000000    \n",
      "==> Top1: 0.000    Top5: 0.000    Loss: 746206963.200\n",
      "\n",
      "==> Best Loss: 746206963.200 on Epoch: 2\n",
      "Saving checkpoint to: ./logs/2018.11.09-104545/checkpoint.pth.tar\n",
      "\n",
      "\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Epoch: [3][    2/41392]    Overall Loss 747446272.000000    Objective Loss 747446272.000000    LR 0.000010    \n",
      "Epoch: [3][    4/41392]    Overall Loss 745924208.000000    Objective Loss 745924208.000000    LR 0.000010    \n",
      "Epoch: [3][    6/41392]    Overall Loss 746291104.000000    Objective Loss 746291104.000000    LR 0.000010    \n",
      "Epoch: [3][    8/41392]    Overall Loss 745652000.000000    Objective Loss 745652000.000000    LR 0.000010    \n",
      "Epoch: [3][   10/41392]    Overall Loss 744270515.200000    Objective Loss 744270515.200000    LR 0.000010    \n",
      "\n",
      "Parameters:\n",
      "+----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n",
      "|    | Name                     | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |\n",
      "|----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|\n",
      "|  0 | conv1.conv2d.weight      | (32, 3, 9, 9)    |          7776 |           3159 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.11150 |  0.00184 |    0.04921 |\n",
      "|  1 | conv2.conv2d.weight      | (64, 32, 3, 3)   |         18432 |           7488 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.13929 | -0.00498 |    0.06527 |\n",
      "|  2 | conv3.conv2d.weight      | (128, 64, 3, 3)  |         73728 |          29952 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.12642 | -0.00160 |    0.06131 |\n",
      "|  3 | res1.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.13937 | -0.01523 |    0.07556 |\n",
      "|  4 | res1.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12740 |  0.00191 |    0.06980 |\n",
      "|  5 | res2.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.13094 | -0.00501 |    0.07279 |\n",
      "|  6 | res2.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12623 |  0.00099 |    0.06929 |\n",
      "|  7 | res3.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12710 | -0.00389 |    0.07036 |\n",
      "|  8 | res3.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12377 |  0.00223 |    0.06758 |\n",
      "|  9 | res4.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.12090 | -0.00159 |    0.06682 |\n",
      "| 10 | res4.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11599 |  0.00133 |    0.06358 |\n",
      "| 11 | res5.conv1.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11606 | -0.00210 |    0.06302 |\n",
      "| 12 | res5.conv2.conv2d.weight | (128, 128, 3, 3) |        147456 |          73728 |          0 |          0 |  0.00000 | 50.00000 | 50.00000 |   50.00000 | 0.11013 |  0.00059 |    0.05926 |\n",
      "| 13 | deconv1.conv2d.weight    | (64, 128, 3, 3)  |         73728 |          29952 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.09867 |  0.00004 |    0.04831 |\n",
      "| 14 | deconv2.conv2d.weight    | (32, 64, 3, 3)   |         18432 |           7488 |          0 |          0 |  0.00000 | 59.37500 | 59.37500 |   59.37500 | 0.08379 | -0.00274 |    0.04089 |\n",
      "| 15 | deconv3.conv2d.weight    | (3, 32, 9, 9)    |          7776 |           5184 |          0 |          0 |  0.00000 | 33.33333 | 33.33333 |   33.33333 | 0.24403 |  0.03671 |    0.14079 |\n",
      "| 16 | Total sparsity:          | -                |       1674432 |         820503 |          0 |          0 |  0.00000 |  0.00000 |  0.00000 |   50.99813 | 0.00000 |  0.00000 |    0.00000 |\n",
      "+----+--------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total sparsity: 51.00\n",
      "\n",
      "--- validate (epoch=3)-----------\n",
      "82783 samples (2 per mini-batch)\n",
      "Training epoch: 82783 samples (2 per mini-batch)\n",
      "Epoch: [3][    2/41391]    Loss 743107296.000000    \n",
      "Epoch: [3][    4/41391]    Loss 741940288.000000    \n",
      "Epoch: [3][    6/41391]    Loss 742724874.666667    \n",
      "Epoch: [3][    8/41391]    Loss 742477520.000000    \n",
      "==> Top1: 0.000    Top5: 0.000    Loss: 741497171.200\n",
      "\n",
      "==> Best Loss: 741497171.200 on Epoch: 3\n",
      "Saving checkpoint to: ./logs/2018.11.09-104545/checkpoint.pth.tar\n"
     ]
    }
   ],
   "source": [
    "check_pytorch_version()\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "msglogger = apputils.config_pylogger(os.path.join(script_dir, 'logging.conf'), args.name, args.output_dir)\n",
    "\n",
    "# Log various details about the execution environment.  It is sometimes useful\n",
    "# to refer to past experiment executions and this information may be useful.\n",
    "apputils.log_execution_env_state(sys.argv, gitroot=module_path)\n",
    "msglogger.debug(\"Distiller: %s\", distiller.__version__)\n",
    "\n",
    "start_epoch = 0\n",
    "best_epochs = [distiller.MutableNamedTuple({'epoch': 0, 'loss': float(\"inf\"), 'sparsity': 0})\n",
    "               for i in range(args.num_best_scores)]\n",
    "\n",
    "if args.deterministic:\n",
    "    # Experiment reproducibility is sometimes important.  Pete Warden expounded about this\n",
    "    # in his blog: https://petewarden.com/2018/03/19/the-machine-learning-reproducibility-crisis/\n",
    "    # In Pytorch, support for deterministic execution is still a bit clunky.\n",
    "    if args.workers > 1:\n",
    "        msglogger.error('ERROR: Setting --deterministic requires setting --workers/-j to 0 or 1')\n",
    "        exit(1)\n",
    "        # Use a well-known seed, for repeatability of experiments\n",
    "        torch.manual_seed(0)\n",
    "        random.seed(0)\n",
    "        np.random.seed(0)\n",
    "        cudnn.deterministic = True\n",
    "    else:\n",
    "        # This issue: https://github.com/pytorch/pytorch/issues/3659\n",
    "        # Implies that cudnn.benchmark should respect cudnn.deterministic, but empirically we see that\n",
    "        # results are not re-produced when benchmark is set. So enabling only if deterministic mode disabled.\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "# if args.gpus is not None:\n",
    "#     try:\n",
    "#         args.gpus = [int(s) for s in args.gpus.split(',')]\n",
    "#     except ValueError:\n",
    "#         msglogger.error('ERROR: Argument --gpus must be a comma-separated list of integers only')\n",
    "#         exit(1)\n",
    "#     available_gpus = torch.cuda.device_count()\n",
    "#     for dev_id in args.gpus:\n",
    "#         if dev_id >= available_gpus:\n",
    "#             msglogger.error('ERROR: GPU device ID {0} requested, but only {1} devices available'\n",
    "#                             .format(dev_id, available_gpus))\n",
    "#             exit(1)\n",
    "#     # Set default device in case the first one on the list != 0\n",
    "#     torch.cuda.set_device(args.gpus[0])\n",
    "    \n",
    "# # Infer the dataset from the model name\n",
    "# args.dataset = 'cifar10' if 'cifar' in args.arch else 'imagenet'\n",
    "# args.num_classes = 10 if args.dataset == 'cifar10' else 1000\n",
    "\n",
    "if args.earlyexit_thresholds:\n",
    "    args.num_exits = len(args.earlyexit_thresholds) + 1\n",
    "    args.loss_exits = [0] * args.num_exits\n",
    "    args.losses_exits = []\n",
    "    args.exiterrors = []\n",
    "    \n",
    "# Create the model\n",
    "model = TransformerNet()\n",
    "if args.cuda:\n",
    "    device = torch.device(\"cuda:{}\".format(args.cuda-1))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "vgg = Vgg16(requires_grad=False).to(device)\n",
    "style_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.mul(255))\n",
    "])\n",
    "if args.pretrained:\n",
    "    resumed_state_dict = torch.load(args.pretrained)\n",
    "    # remove saved deprecated running_* keys in InstanceNorm from the checkpoint\n",
    "    for k in list(resumed_state_dict.keys()):\n",
    "        if re.search(r'in\\d+\\.running_(mean|var)$', k):\n",
    "            del resumed_state_dict[k]\n",
    "    model.load_state_dict(resumed_state_dict)\n",
    "    msglogger.info('Loaded pretrained model from %s\\n', args.pretrained)\n",
    "    \n",
    "\n",
    "compression_scheduler = None\n",
    "# Create a couple of logging backends.  TensorBoardLogger writes log files in a format\n",
    "# that can be read by Google's Tensor Board.  PythonLogger writes to the Python logger.\n",
    "tflogger = TensorBoardLogger(msglogger.logdir)\n",
    "pylogger = PythonLogger(msglogger)\n",
    "\n",
    "# capture thresholds for early-exit training\n",
    "if args.earlyexit_thresholds:\n",
    "    msglogger.info('=> using early-exit threshold values of %s', args.earlyexit_thresholds)\n",
    "\n",
    "# We can optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    model, compression_scheduler, start_epoch = apputils.load_checkpoint(\n",
    "        model, chkpt_file=args.resume)\n",
    "    \n",
    "# Define loss function (criterion) and optimizer\n",
    "optimizer = Adam(model.parameters(), args.lr)\n",
    "msglogger.info('Optimizer Type: %s', type(optimizer))\n",
    "msglogger.info('Optimizer Args: %s', optimizer.defaults)\n",
    "\n",
    "# This sample application can be invoked to produce various summary reports.\n",
    "# if args.summary:\n",
    "    # return summarize_model(model, args.dataset, which_summary=args.summary)\n",
    "    \n",
    "# Load the datasets: the dataset to load is inferred from the model name passed\n",
    "# in args.arch.  The default dataset is ImageNet, but if args.arch contains the\n",
    "# substring \"_cifar\", then cifar10 is used.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(args.image_size),\n",
    "    transforms.CenterCrop(args.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.mul(255))\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(args.dataset, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size)\n",
    "msglogger.info('Dataset sizes:\\n\\ttraining=%d\\n',\n",
    "               len(train_loader.sampler))\n",
    "\n",
    "activations_collectors = create_activation_stats_collectors(model, collection_phase=args.activation_stats)\n",
    "\n",
    "if args.compress:\n",
    "    # The main use-case for this sample application is CNN compression. Compression\n",
    "    # requires a compression schedule configuration file in YAML.\n",
    "    compression_scheduler = distiller.file_config(model, optimizer, args.compress)\n",
    "#     # Model is re-transferred to GPU in case parameters were added (e.g. PACTQuantizer)\n",
    "#     model.cuda()\n",
    "    model.to(device)\n",
    "else:\n",
    "    compression_scheduler = distiller.CompressionScheduler(model)\n",
    "        \n",
    "for epoch in range(start_epoch, start_epoch + args.epochs):\n",
    "    # This is the main training loop.\n",
    "    msglogger.info('\\n')\n",
    "    if compression_scheduler:\n",
    "        compression_scheduler.on_epoch_begin(epoch)\n",
    "        \n",
    "        # Train for one epoch\n",
    "        with collectors_context(activations_collectors[\"train\"]) as collectors:\n",
    "            train(train_loader, model, optimizer, vgg, epoch, compression_scheduler, [tflogger, pylogger],\n",
    "                  args.log_interval, args.style_image, args.style_size, args.content_weight, args.style_weight)\n",
    "            distiller.log_weights_sparsity(model, epoch, loggers=[tflogger, pylogger])\n",
    "            distiller.log_activation_statsitics(epoch, \"train\", loggers=[tflogger],\n",
    "                                                collector=collectors[\"sparsity\"])\n",
    "            if args.masks_sparsity:\n",
    "                msglogger.info(distiller.masks_sparsity_tbl_summary(model, compression_scheduler))\n",
    "                \n",
    "        # evaluate on validation set\n",
    "        with collectors_context(activations_collectors[\"valid\"]) as collectors:\n",
    "            top1, top5, vloss = validate(train_loader, model, None, [pylogger], args, epoch)\n",
    "            distiller.log_activation_statsitics(epoch, \"valid\", loggers=[tflogger],\n",
    "                                                collector=collectors[\"sparsity\"])\n",
    "            save_collectors_data(collectors, msglogger.logdir)\n",
    "            \n",
    "        if compression_scheduler:\n",
    "            compression_scheduler.on_epoch_end(epoch, optimizer)\n",
    "\n",
    "        # remember best top1 and save checkpoint\n",
    "        is_best = vloss < best_epochs[0].loss\n",
    "        if is_best:\n",
    "            best_epochs[0].epoch = epoch\n",
    "            best_epochs[0].loss = vloss\n",
    "            best_epochs = sorted(best_epochs, key=lambda score: score.loss, reverse=True)\n",
    "        for score in reversed(best_epochs):\n",
    "            if score.loss > 0:\n",
    "                msglogger.info('==> Best Loss: %.3f on Epoch: %d', score.loss, score.epoch)\n",
    "        apputils.save_checkpoint(epoch, None, model, optimizer, compression_scheduler,\n",
    "                                 best_epochs[0].loss, is_best, args.name, msglogger.logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERALL_LOSS_KEY = 'Overall Loss'\n",
    "OBJECTIVE_LOSS_KEY = 'Objective Loss'\n",
    "\n",
    "def train(train_loader, model, optimizer, vgg, epoch, compression_scheduler, loggers,\n",
    "          log_interval, style_image, style_size, content_weight, style_weight):\n",
    "#     np.random.seed(args.seed)\n",
    "#     torch.manual_seed(args.seed)\n",
    "    \"\"\"Training loop for one epoch.\"\"\"\n",
    "    losses = OrderedDict([(OVERALL_LOSS_KEY, tnt.AverageValueMeter()),\n",
    "                          (OBJECTIVE_LOSS_KEY, tnt.AverageValueMeter())])\n",
    "   \n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    \n",
    "    total_samples = len(train_loader.sampler)\n",
    "    batch_size = train_loader.batch_size\n",
    "    steps_per_epoch = math.ceil(total_samples / batch_size)\n",
    "    msglogger.info('Training epoch: %d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "    \n",
    "    style = utils.load_image(style_image, size=style_size)\n",
    "    style = style_transform(style)\n",
    "    style = style.repeat(batch_size, 1, 1, 1).to(device)\n",
    "    \n",
    "    features_style = vgg(utils.normalize_batch(style))\n",
    "    gram_style = [utils.gram_matrix(y) for y in features_style]\n",
    "    \n",
    "    model.train()\n",
    "    agg_content_loss = 0.\n",
    "    agg_style_loss = 0.\n",
    "    count = 0\n",
    "    end = time.time()\n",
    "    for batch_id, (x, _) in enumerate(train_loader):\n",
    "        n_batch = len(x)\n",
    "        count += n_batch\n",
    "        \n",
    "        # Execute the forward phase, compute the output and measure loss\n",
    "        if compression_scheduler:\n",
    "            compression_scheduler.on_minibatch_begin(epoch, batch_id, steps_per_epoch, optimizer)\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = model(x)\n",
    "\n",
    "        y = utils.normalize_batch(y)\n",
    "        x = utils.normalize_batch(x)\n",
    "\n",
    "        features_y = vgg(y)\n",
    "        features_x = vgg(x)\n",
    "\n",
    "        content_loss = content_weight * mse_loss(features_y.relu2_2, features_x.relu2_2)\n",
    "\n",
    "        style_loss = 0.\n",
    "        for ft_y, gm_s in zip(features_y, gram_style):\n",
    "            gm_y = utils.gram_matrix(ft_y)\n",
    "            style_loss += mse_loss(gm_y, gm_s[:n_batch, :, :])\n",
    "        style_loss *= style_weight\n",
    "\n",
    "        loss = content_loss + style_loss\n",
    "\n",
    "        losses[OBJECTIVE_LOSS_KEY].add(loss.item())\n",
    "        \n",
    "        if compression_scheduler:\n",
    "            # Before running the backward phase, we allow the scheduler to modify the loss\n",
    "            # (e.g. add regularization loss)\n",
    "            agg_loss = compression_scheduler.before_backward_pass(epoch, batch_id, steps_per_epoch, loss,\n",
    "                                                                  optimizer=optimizer, return_loss_components=True)\n",
    "            loss = agg_loss.overall_loss\n",
    "            losses[OVERALL_LOSS_KEY].add(loss.item())\n",
    "            for lc in agg_loss.loss_components:\n",
    "                if lc.name not in losses:\n",
    "                    losses[lc.name] = tnt.AverageValueMeter()\n",
    "                losses[lc.name].add(lc.value.item())\n",
    "        \n",
    "        # Compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if compression_scheduler:\n",
    "            compression_scheduler.on_minibatch_end(epoch, batch_id, steps_per_epoch, optimizer)\n",
    "        \n",
    "        if batch_id == 10:\n",
    "            return\n",
    "        if (batch_id + 1) % log_interval == 0:\n",
    "            stats_dict = OrderedDict()\n",
    "            for loss_name, meter in losses.items():\n",
    "                stats_dict[loss_name] = meter.mean\n",
    "            # stats_dict.update(errs)\n",
    "            stats_dict['LR'] = optimizer.param_groups[0]['lr']\n",
    "            # stats_dict['Time'] = batch_time.mean\n",
    "            stats = ('Peformance/Training/', stats_dict)\n",
    "\n",
    "            params = model.named_parameters() if args.log_params_histograms else None\n",
    "            distiller.log_training_progress(stats,\n",
    "                                            params,\n",
    "                                            epoch, batch_id+1,\n",
    "                                            steps_per_epoch, log_interval,\n",
    "                                            loggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, loggers, args, epoch=-1):\n",
    "    \"\"\"Model validation\"\"\"\n",
    "    if epoch > -1:\n",
    "        msglogger.info('--- validate (epoch=%d)-----------', epoch)\n",
    "    else:\n",
    "        msglogger.info('--- validate ---------------------')\n",
    "    return _validate(val_loader, model, criterion, loggers, args, epoch)\n",
    "\n",
    "def _validate(data_loader, model, criterion, loggers, args, epoch=-1):\n",
    "    \"\"\"Execute the validation/test loop.\"\"\"\n",
    "    losses = {'objective_loss': tnt.AverageValueMeter()}\n",
    "    # classerr = tnt.ClassErrorMeter(accuracy=True, topk=(1, 5))\n",
    "\n",
    "    if args.earlyexit_thresholds:\n",
    "        # for Early Exit, we have a list of errors and losses for each of the exits.\n",
    "        args.exiterrors = []\n",
    "        args.losses_exits = []\n",
    "        for exitnum in range(args.num_exits):\n",
    "            # args.exiterrors.append(tnt.ClassErrorMeter(accuracy=True, topk=(1, 5)))\n",
    "            args.losses_exits.append(tnt.AverageValueMeter())\n",
    "        args.exit_taken = [0] * args.num_exits\n",
    "\n",
    "    batch_time = tnt.AverageValueMeter()\n",
    "    total_samples = len(data_loader.sampler)\n",
    "    batch_size = data_loader.batch_size\n",
    "    if args.display_confusion:\n",
    "        confusion = tnt.ConfusionMeter(args.num_classes)\n",
    "    total_steps = total_samples / batch_size\n",
    "    msglogger.info('%d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    steps_per_epoch = math.ceil(total_samples / batch_size)\n",
    "    msglogger.info('Training epoch: %d samples (%d per mini-batch)', total_samples, batch_size)\n",
    "    \n",
    "    style = utils.load_image(args.style_image, size=args.style_size)\n",
    "    style = style_transform(style)\n",
    "    style = style.repeat(batch_size, 1, 1, 1).to(device)\n",
    "    \n",
    "    features_style = vgg(utils.normalize_batch(style))\n",
    "    gram_style = [utils.gram_matrix(y) for y in features_style]\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for validation_step, (x, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():            \n",
    "            if not args.earlyexit_thresholds:\n",
    "                n_batch = len(x)\n",
    "                x = x.to(device)\n",
    "                y = model(x)\n",
    "\n",
    "                y = utils.normalize_batch(y)\n",
    "                x = utils.normalize_batch(x)\n",
    "\n",
    "                features_y = vgg(y)\n",
    "                features_x = vgg(x)\n",
    "\n",
    "                content_loss = args.content_weight * mse_loss(features_y.relu2_2, features_x.relu2_2)\n",
    "\n",
    "                style_loss = 0.\n",
    "                for ft_y, gm_s in zip(features_y, gram_style):\n",
    "                    gm_y = utils.gram_matrix(ft_y)\n",
    "                    style_loss += mse_loss(gm_y, gm_s[:n_batch, :, :])\n",
    "                style_loss *= args.style_weight\n",
    "\n",
    "                loss = content_loss + style_loss\n",
    "                \n",
    "                losses['objective_loss'].add(loss.item())\n",
    "                # classerr.add(output.data, target)\n",
    "                if args.display_confusion:\n",
    "                    confusion.add(output.data, target)\n",
    "            else:\n",
    "                earlyexit_validate_loss(output, target, criterion, args)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.add(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            steps_completed = (validation_step+1)\n",
    "            if steps_completed == 10:\n",
    "                break\n",
    "            if steps_completed % args.log_interval == 0:\n",
    "                if not args.earlyexit_thresholds:\n",
    "                    stats = ('',\n",
    "                             OrderedDict([('Loss', losses['objective_loss'].mean)]))\n",
    "#                             OrderedDict([('Loss', losses['objective_loss'].mean),\n",
    "#                                          ('Top1', classerr.value(1)),\n",
    "#                                          ('Top5', classerr.value(5))]))\n",
    "                else:\n",
    "                    stats_dict = OrderedDict()\n",
    "                    stats_dict['Test'] = validation_step\n",
    "                    for exitnum in range(args.num_exits):\n",
    "                        la_string = 'LossAvg' + str(exitnum)\n",
    "                        stats_dict[la_string] = args.losses_exits[exitnum].mean\n",
    "                        # Because of the nature of ClassErrorMeter, if an exit is never taken during the batch,\n",
    "                        # then accessing the value(k) will cause a divide by zero. So we'll build the OrderedDict\n",
    "                        # accordingly and we will not print for an exit error when that exit is never taken.\n",
    "                        if args.exit_taken[exitnum]:\n",
    "                            t1 = 'Top1_exit' + str(exitnum)\n",
    "                            t5 = 'Top5_exit' + str(exitnum)\n",
    "                            stats_dict[t1] = args.exiterrors[exitnum].value(1)\n",
    "                            stats_dict[t5] = args.exiterrors[exitnum].value(5)\n",
    "                    stats = ('Performance/Validation/', stats_dict)\n",
    "\n",
    "                distiller.log_training_progress(stats, None, epoch, steps_completed,\n",
    "                                                total_steps, args.log_interval, loggers)\n",
    "    if not args.earlyexit_thresholds:\n",
    "        msglogger.info('==> Top1: %.3f    Top5: %.3f    Loss: %.3f\\n',\n",
    "                       0, 0, losses['objective_loss'].mean)\n",
    "\n",
    "        if args.display_confusion:\n",
    "            msglogger.info('==> Confusion:\\n%s\\n', str(confusion.value()))\n",
    "        return 0, 0, losses['objective_loss'].mean\n",
    "    else:\n",
    "        total_top1, total_top5, losses_exits_stats = earlyexit_validate_stats(args)\n",
    "        return total_top1, total_top5, losses_exits_stats[args.num_exits-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the gradual sparsity function\n",
    "\n",
    "The function ```sparsity_target``` implements the gradual sparsity schedule from [[1]](#zhu-gupta):<br><br>\n",
    "<b><i>\"We introduce a new automated gradual pruning algorithm in which the sparsity is increased from an initial sparsity value $s_i$ (usually 0) to a final sparsity value $s_f$ over a span of $n$ pruning steps, starting at training step $t_0$ and with pruning frequency $\\Delta t$.\"</i></b><br>\n",
    "<br>\n",
    "\n",
    "<div id=\"eq:zhu_gupta_schedule\"></div>\n",
    "<center>\n",
    "$\\large\n",
    "\\begin{align}\n",
    "s_t = s_f + (s_i - s_f) \\left(1- \\frac{t-t_0}{n\\Delta t}\\right)^3\n",
    "\\end{align}\n",
    "\\ \\ for\n",
    "\\large \\ \\ t \\in \\{t_0, t_0+\\Delta t, ..., t_0+n\\Delta t\\}\n",
    "$\n",
    "</center>\n",
    "<br>\n",
    "Pruning happens once at the beginning of each epoch, until the duration of the pruning (the number of epochs to prune) is exceeded.  After pruning ends, the training continues without pruning, but the pruned weights are kept at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity_target(starting_epoch, ending_epoch, initial_sparsity, final_sparsity, current_epoch):\n",
    "    if final_sparsity < initial_sparsity:\n",
    "        return current_epoch \n",
    "    if current_epoch < starting_epoch:\n",
    "        return current_epoch\n",
    "    \n",
    "    span = ending_epoch - starting_epoch\n",
    "    target_sparsity = ( final_sparsity +\n",
    "                        (initial_sparsity - final_sparsity) *\n",
    "                        (1.0 - ((current_epoch-starting_epoch)/span))**3)\n",
    "    return target_sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize pruning schedule\n",
    "When using the Automated Gradual Pruning (AGP) schedule, you may want to visualize how the pruning schedule will look as a function of the epoch number.  This is called the *sparsity function*.  The widget below will help you do this.<br>\n",
    "There are three knobs you can use to change the schedule:\n",
    "- ```duration```: this is the number of epochs over which to use the AGP schedule ($n\\Delta t$).\n",
    "- ```initial_sparsity```: $s_i$\n",
    "- ```final_sparsity```: $s_f$\n",
    "- ```frequency```: this is the pruning frequency ($\\Delta t$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pruning(duration, initial_sparsity, final_sparsity, frequency):\n",
    "    epochs = []\n",
    "    sparsity_levels = []\n",
    "    # The derivative of the sparsity (i.e. sparsity rate of change)\n",
    "    d_sparsity = []\n",
    "\n",
    "    if frequency=='':\n",
    "        frequency = 1 \n",
    "    else:\n",
    "        frequency = int(frequency)\n",
    "    for epoch in range(0,40):\n",
    "        epochs.append(epoch)\n",
    "        current_epoch=Variable(torch.FloatTensor([epoch]), requires_grad=True)\n",
    "        if epoch<duration and epoch%frequency == 0:\n",
    "            sparsity = sparsity_target(\n",
    "                     starting_epoch=0, \n",
    "                     ending_epoch=duration, \n",
    "                     initial_sparsity=initial_sparsity, \n",
    "                     final_sparsity=final_sparsity,\n",
    "                current_epoch=current_epoch\n",
    "            )\n",
    "            \n",
    "            sparsity_levels.append(sparsity)\n",
    "            sparsity.backward()\n",
    "            d_sparsity.append(current_epoch.grad.item())\n",
    "            current_epoch.grad.data.zero_()\n",
    "        else:\n",
    "            sparsity_levels.append(sparsity)\n",
    "            d_sparsity.append(0)\n",
    "            \n",
    "\n",
    "    plt.plot(epochs, sparsity_levels, epochs, d_sparsity)\n",
    "    plt.ylabel('sparsity (%)')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Pruning Rate')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "duration_widget = widgets.IntSlider(min=0, max=100, step=1, value=28)\n",
    "si_widget = widgets.IntSlider(min=0, max=100, step=1, value=0)\n",
    "interact(draw_pruning, \n",
    "         duration=duration_widget, \n",
    "         initial_sparsity=si_widget, \n",
    "         final_sparsity=(0,100,1),\n",
    "         frequency='2'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>\n",
    "## References\n",
    "1. <div id=\"zhu-gupta\"></div> **Michael Zhu and Suyog Gupta**. \n",
    "    [*To prune, or not to prune: exploring the efficacy of pruning for model compression*](https://arxiv.org/pdf/1710.01878),\n",
    "    NIPS Workshop on Machine Learning of Phones and other Consumer Devices,\n",
    "    2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
